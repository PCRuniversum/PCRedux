@comment{x-kbibtex-personnameformatting=<%f ><%l><, %s>}

@article{roediger2015r,
	author = "Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Konstantin A. Blagodatskikh and Peter Schierack",
	journal = "The R Journal",
	number = "2",
	pages = "127--150",
	title = "{R as an {Environment} for the {Reproducible} {Analysis} of {DNA} {Amplification} {Experiments}}",
	url = "http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf",
	volume = "7",
	year = "2015"
}

@article{liaw_classification_2002,
	author = "Andy Liaw and Matthew Wiener",
	journal = "R News",
	number = "3",
	pages = "18--22",
	title = "{Classification and {Regression} by {randomForest}}",
	url = "http://CRAN.R-project.org/doc/Rnews/",
	volume = "2",
	year = "2002"
}

@article{breiman_random_2001,
	author = "Leo Breiman",
	journal = "Machine learning",
	number = "1",
	pages = "5--32",
	title = "{Random forests}",
	volume = "45",
	year = "2001"
}

@book{noauthor_compstat_2008,
	abstract = "COMPSTAT 2008...",
	editor = "Paula Brito",
	file = "Snapshot:/home/tux/Work/Literatur/Zotero\_DB/zotero/storage/FYA8ZYXJ/9783790820836.html:text/html",
	isbn = "978-3-7908-2083-6",
	language = "en",
	localfile = "//www.springer.com/us/book/9783790820836",
	publisher = "Physica-Verlag Heidelberg",
	shorttitle = "{COMPSTAT} 2008",
	title = "{{COMPSTAT} 2008: {Proceedings} in {Computational} {Statistics}}",
	urldate = "2018-03-03",
	year = "2008"
}

@article{pabinger_2014,
	abstract = "Real-time quantitative polymerase-chain-reaction (qPCR) is a standard technique in most laboratories used for various applications in basic research. Analysis of qPCR data is a crucial part of the entire experiment, which has led to the development of a plethora of methods. The released tools either cover specific parts of the workflow or provide complete analysis solutions. Here, we surveyed 27 open-access software packages and tools for the analysis of qPCR data. The survey includes 8 Microsoft Windows, 5 web-based, 9 R-based and 5 tools from other platforms. Reviewed packages and tools support the analysis of different qPCR applications, such as RNA quantification, DNA methylation, genotyping, identification of copy number variations, and digital PCR. We report an overview of the functionality, features and specific requirements of the individual software tools, such as data exchange formats, availability of a graphical user interface, included procedures for graphical data presentation, and offered statistical methods. In addition, we provide an overview about quantification strategies, and report various applications of qPCR. Our comprehensive survey showed that most tools use their own file format and only a fraction of the currently existing tools support the standardized data exchange format RDML. To allow a more streamlined and comparable analysis of qPCR data, more vendors and tools need to adapt the standardized format to encourage the exchange of data between instrument software, analysis tools, and researchers.",
	author = "Stephan Pabinger and Stefan R{\"o}diger and Albert Kriegner and Klemens Vierlinger and Andreas Weinh{\"a}usel",
	doi = "10.1016/j.bdq.2014.08.002",
	issn = "2214-7535",
	journal = "Biomolecular Detection and Quantification",
	keywords = "Data analysis; MIQE; qPCR; RDML; Software; Tools",
	month = sep,
	note = "00003",
	number = "1",
	pages = "23--33",
	title = "{A survey of tools for the analysis of quantitative {PCR} ({qPCR}) data}",
	url = "http://www.sciencedirect.com/science/article/pii/S2214753514000059",
	urldate = "2015-04-02",
	volume = "1",
	year = "2014"
}

@article{roediger_rkward_2012,
	abstract = "R is a free open-source implementation of the S statistical computing language and programming environment. The current status of R is a command line driven interface with no advanced cross-platform graphical user interface (GUI), but it includes tools for building such. Over the past years, proprietary and non-proprietary GUI solutions have emerged, based on internal or external tool kits, with different scopes and technological concepts. For example, Rgui.exe and Rgui.app have become the de facto GUI on the Microsoft Windows and Mac OS X platforms, respectively, for most users. In this paper we discuss RKWard which aims to be both a comprehensive GUI and an integrated development environment for R. RKWard is based on the KDE software libraries. Statistical procedures and plots are implemented using an extendable plugin architecture based on ECMAScript (JavaScript), R, and XML. RKWard provides an excellent tool to manage different types of data objects; even allowing for seamless editing of certain types. The objective of RKWard is to provide a portable and extensible R interface for both basic and advanced statistical and graphical analysis, while not compromising on flexibility and modularity of the R programming environment itself.",
	author = "Stefan R{\"o}diger and Thomas Friedrichsmeier and Prasenjit Kapat and Meik Michalke",
	journal = "Journal of Statistical Software",
	number = "9",
	pages = "1--34",
	shorttitle = "{RKWard}",
	title = "{{RKWard}: a comprehensive graphical user interface and integrated development environment for statistical analysis with {R}}",
	url = "https://www.jstatsoft.org/article/view/v049i09/v49i09.pdf",
	volume = "49",
	year = "2012"
}

@article{spiess_impact_2015,
	abstract = "BACKGROUND: Quantification cycle (Cq) and amplification efficiency (AE) are parameters mathematically extracted from raw data to characterize quantitative PCR (qPCR) reactions and quantify the copy number in a sample. Little attention has been paid to the effects of preprocessing and the use of smoothing or filtering approaches to compensate for noisy data. Existing algorithms largely are taken for granted, and it is unclear which of the various methods is most informative. We investigated the effect of smoothing and filtering algorithms on amplification curve data. METHODS: We obtained published high-replicate qPCR data sets from standard block thermocyclers and other cycler platforms and statistically evaluated the impact of smoothing on Cq and AE. RESULTS: Our results indicate that selected smoothing algorithms affect estimates of Cq and AE considerably. The commonly used moving average filter performed worst in all qPCR scenarios. The Savitzky--Golay smoother, cubic splines, and Whittaker smoother resulted overall in the least bias in our setting and exhibited low sensitivity to differences in qPCR AE, whereas other smoothers, such as running mean, introduced an AE-dependent bias. CONCLUSIONS: The selection of a smoothing algorithm is an important step in developing data analysis pipelines for real-time PCR experiments. We offer guidelines for selection of an appropriate smoothing algorithm in diagnostic qPCR applications. The findings of our study were implemented in the R packages chipPCR and qpcR as a basis for the implementation of an analytical strategy.",
	author = "Andrej-Nikolai Spiess and Claudia Deutschmann and Micha{\l} Burdukiewicz and Ralf Himmelreich and Katharina Klat and Peter Schierack and Stefan R{\"o}diger",
	doi = "10.1373/clinchem.2014.230656",
	issn = "0009-9147, 1530-8561",
	journal = "Clinical Chemistry",
	language = "en",
	month = feb,
	number = "2",
	pages = "379--388",
	title = "{Impact of {Smoothing} on {Parameter} {Estimation} in {Quantitative} {DNA} {Amplification} {Experiments}}",
	urldate = "2016-12-03",
	volume = "61",
	year = "2015"
}

@article{ruijter_amplification_2009,
	abstract = "Despite the central role of quantitative PCR (qPCR) in the quantification of mRNA transcripts, most analyses of qPCR data are still delegated to the software that comes with the qPCR apparatus. This is especially true for the handling of the fluorescence baseline. This article shows that baseline estimation errors are directly reflected in the observed PCR efficiency values and are thus propagated exponentially in the estimated starting concentrations as well as 'fold-difference' results. Because of the unknown origin and kinetics of the baseline fluorescence, the fluorescence values monitored in the initial cycles of the PCR reaction cannot be used to estimate a useful baseline value. An algorithm that estimates the baseline by reconstructing the log-linear phase downward from the early plateau phase of the PCR reaction was developed and shown to lead to very reproducible PCR efficiency values. PCR efficiency values were determined per sample by fitting a regression line to a subset of data points in the log-linear phase. The variability, as well as the bias, in qPCR results was significantly reduced when the mean of these PCR efficiencies per amplicon was used in the calculation of an estimate of the starting concentration per sample.",
	author = "J M Ruijter and C Ramakers and W M H Hoogaars and Y Karlen and O Bakker and M J B van den Hoff and A F M Moorman",
	doi = "10.1093/nar/gkp045",
	issn = "1362-4962",
	journal = "Nucleic Acids Research",
	keywords = "Algorithms; Animals; Chick Embryo; Fluorescence; Linear Models; Reverse Transcriptase Polymerase Chain Reaction",
	language = "eng",
	month = apr,
	number = "6",
	pages = "e45",
	pmcid = "PMC2665230",
	pmid = "19237396",
	shorttitle = "Amplification efficiency",
	title = "{Amplification efficiency: linking baseline and bias in the analysis of quantitative {PCR} data}",
	volume = "37",
	year = "2009"
}

@article{lefever_rdml_2009,
	abstract = "The XML-based Real-Time PCR Data Markup Language (RDML) has been developed by the RDML consortium (http://www.rdml.org) to enable straightforward exchange of qPCR data and related information between qPCR instruments and third party data analysis software, between colleagues and collaborators and between experimenters and journals or public repositories. We here also propose data related guidelines as a subset of the Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) to guarantee inclusion of key data information when reporting experimental results.",
	author = "Steve Lefever and Jan Hellemans and Filip Pattyn and Daniel R. Przybylski and Chris Taylor and Ren{\'e} Geurts and Andreas Untergasser and Jo Vandesompele and on behalf of the RDML Consortium",
	doi = "10.1093/nar/gkp056",
	issn = "0305-1048, 1362-4962",
	journal = "Nucleic Acids Research",
	language = "en",
	month = apr,
	note = "00097",
	number = "7",
	pages = "2065--2069",
	pmid = "19223324",
	shorttitle = "{RDML}",
	title = "{{RDML}: structured language and reporting guidelines for real-time quantitative {PCR} data}",
	url = "http://nar.oxfordjournals.org/content/37/7/2065",
	urldate = "2015-04-01",
	volume = "37",
	year = "2009"
}

@article{ruijter_rdml-ninja_2015,
	abstract = "BackgroundThe universal qPCR data exchange file format RDML is today well accepted by the scientific community, part of the MIQE guidelines and implemented in many qPCR instruments. With the increased use of RDML new challenges emerge. The flexibility of the RDML format resulted in some implementations that did not meet the expectations of the consortium in the level of support or the use of elements.ResultsIn the current RDML version 1.2 the description of the elements was sharpened. The open source editor RDML-Ninja was released (http://sourceforge.net/projects/qpcr-ninja/). RDML-Ninja allows to visualize, edit and validate RDML files and thus clarifies the use of RDML elements. Furthermore RDML-Ninja serves as reference implementation for RDML and enables migration between RDML versions independent of the instrument software. The database RDMLdb will serve as an online repository for RDML files and facilitate the exchange of RDML data (http://www.rdmldb.org). Authors can upload their RDML files and reference them in publications by the unique identifier provided by RDMLdb. The MIQE guidelines propose a rich set of information required to document each qPCR run. RDML provides the vehicle to store and maintain this information and current development aims at further integration of MIQE requirements into the RDML format.ConclusionsThe editor RDML-Ninja and the database RDMLdb enable scientists to evaluate and exchange qPCR data in the instrument-independent RDML format. We are confident that this infrastructure will build the foundation for standardized qPCR data exchange among scientists, research groups, and during publication.",
	author = "Jan M. Ruijter and Steve Lefever and Jasper Anckaert and Jan Hellemans and Michael W. Pfaffl and Vladimir Benes and Stephen A. Bustin and Jo Vandesompele and Andreas Untergasser and on behalf of the RDML Consortium",
	doi = "10.1186/s12859-015-0637-6",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	language = "en",
	month = dec,
	number = "1",
	pages = "197",
	title = "{{RDML}-{Ninja} and {RDMLdb} for standardized exchange of {qPCR} data}",
	urldate = "2017-09-04",
	volume = "16",
	year = "2015"
}

@article{pabinger_qpcr:_2009,
	abstract = "Since its introduction quantitative real-time polymerase chain reaction (qPCR) has become the standard method for quantification of gene expression. Its high sensitivity, large dynamic range, and accuracy led to the development of numerous applications with an increasing number of samples to be analyzed. Data analysis consists of a number of steps, which have to be carried out in several different applications. Currently, no single tool is available which incorporates storage, management, and multiple methods covering the complete analysis pipeline. PMID: 19712446",
	author = "Stephan Pabinger and Gerhard G. Thallinger and Ren{\'e} Snajder and Heiko Eichhorn and Robert Rader and Zlatko Trajanoski",
	copyright = "2009 Pabinger et al; licensee BioMed Central Ltd.",
	doi = "10.1186/1471-2105-10-268",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	language = "en",
	month = aug,
	number = "1",
	pages = "268",
	pmid = "19712446",
	shorttitle = "{QPCR}",
	title = "{{QPCR}: {Application} for real-time {PCR} data management and analysis}",
	url = "http://www.biomedcentral.com/1471-2105/10/268/abstract",
	urldate = "2014-07-01",
	volume = "10",
	year = "2009"
}

@article{neve_unifiedwmwqpcr:_2014,
	abstract = "Motivation: Recently, De Neve et al. proposed a modification of the Wilcoxon--Mann--Whitney (WMW) test for assessing differential expression based on RT-qPCR data. Their test, referred to as the unified WMW (uWMW) test, incorporates a robust and intuitive normalization and quantifies the probability that the expression from one treatment group exceeds the expression from another treatment group. However, no software package for this test was available yet. Results: We have developed a Bioconductor package for analyzing RT-qPCR data with the uWMW test. The package also provides graphical tools for visualizing the effect sizes. Availability and implementation: The unifiedWMWqPCR package and its user documentation can be obtained through Bioconductor. Contact: JanR.DeNeve@UGent.be",
	author = "Jan De Neve and Joris Meys and Jean-Pierre Ottoy and Lieven Clement and Olivier Thas",
	doi = "10.1093/bioinformatics/btu313",
	issn = "1367-4803, 1460-2059",
	journal = "Bioinformatics",
	language = "en",
	month = sep,
	number = "17",
	pages = "2494--2495",
	pmid = "24794933",
	shorttitle = "{unifiedWMWqPCR}",
	title = "{{unifiedWMWqPCR}: the unified {Wilcoxon}--{Mann}--{Whitney} test for analyzing {RT}-{qPCR} data in {R}}",
	url = "http://bioinformatics.oxfordjournals.org/content/30/17/2494",
	urldate = "2014-09-21",
	volume = "30",
	year = "2014"
}

@article{mccall_non-detects_2014,
	abstract = "Motivation: Quantitative real-time PCR (qPCR) is one of the most widely used methods to measure gene expression. Despite extensive research in qPCR laboratory protocols, normalization and statistical analysis, little attention has been given to qPCR non-detects---those reactions failing to produce a minimum amount of signal., Results: We show that the common methods of handling qPCR non-detects lead to biased inference. Furthermore, we show that non-detects do not represent data missing completely at random and likely represent missing data occurring not at random. We propose a model of the missing data mechanism and develop a method to directly model non-detects as missing data. Finally, we show that our approach results in a sizeable reduction in bias when estimating both absolute and differential gene expression., Availability and implementation: The proposed algorithm is implemented in the R package, nondetects. This package also contains the raw data for the three example datasets used in this manuscript. The package is freely available at http://mnmccall.com/software and as part of the Bioconductor project., Contact: mccallm@gmail.com",
	author = "Matthew N. McCall and Helene R. McMurray and Hartmut Land and Anthony Almudevar",
	doi = "10.1093/bioinformatics/btu239",
	issn = "1367-4803",
	journal = "Bioinformatics",
	month = aug,
	number = "16",
	pages = "2310--2316",
	pmcid = "PMC4133581",
	pmid = "24764462",
	title = "{On non-detects in {qPCR} data}",
	url = "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4133581/",
	urldate = "2016-09-28",
	volume = "30",
	year = "2014"
}

@article{ruijter_removal_2015,
	abstract = "Quantitative PCR (qPCR) is the method of choice in gene expression analysis. However, the number of groups or treatments, target genes and technical replicates quickly exceeds the capacity of a single run on a qPCR machine and the measurements have to be spread over more than 1 plate. Such multi-plate measurements often show similar proportional differences between experimental conditions, but different absolute values, even though the measurements were technically carried out with identical procedures. Removal of this between-plate variation will enhance the power of the statistical analysis on the resulting data. Inclusion and application of calibrator samples, with replicate measurements distributed over the plates, assumes a multiplicative difference between plates. However, random and technical errors in these calibrators will propagate to all samples on the plate. To avoid this effect, the systematic bias between plates can be removed with a correction factor based on all overlapping technical and biological replicates between plates. This approach removes the requirement for all calibrator samples to be measured successfully on every plate. This paper extends an already published factor correction method to the use in multi-plate qPCR experiments. The between-run correction factor is derived from the target quantities which are calculated from the quantification threshold, PCR efficiency and observed Cq value. To enable further statistical analysis in existing qPCR software packages, an efficiency-corrected Cq value is reported, based on the corrected target quantity and a PCR efficiency per target. The latter is calculated as the mean of the PCR efficiencies taking the number of reactions per amplicon per plate into account. Export to the RDML format completes an RDML-supported analysis pipeline of qPCR data ranging from raw fluorescence data, amplification curve analysis and application of reference genes to statistical analysis.",
	author = "Jan M. Ruijter and Adri{\'a}n {Ruiz Villalba} and Jan Hellemans and Andreas Untergasser and Maurice J. B. van den Hoff",
	doi = "10.1016/j.bdq.2015.07.001",
	issn = "2214-7535",
	journal = "Biomolecular Detection and Quantification",
	keywords = "Between-plate correction; Between-run variation; Multi-plate experiment; qPCR; RDML; Software",
	month = sep,
	pages = "10--14",
	series = "{Special {Issue}: {Advanced} {Molecular} {Diagnostics} for {Biomarker} {Discovery} -- {Part} {I}}",
	title = "{Removal of between-run variation in a multi-plate {qPCR} experiment}",
	url = "http://www.sciencedirect.com/science/article/pii/S2214753515300012",
	urldate = "2016-11-08",
	volume = "5",
	year = "2015"
}

@article{dvinge_htqpcr:_2009,
	abstract = "Motivation: Quantitative real-time polymerase chain reaction (qPCR) is routinely used for RNA expression profiling, validation of microarray hybridization data and clinical diagnostic assays. Although numerous statistical tools are available in the public domain for the analysis of microarray experiments, this is not the case for qPCR. Proprietary software is typically provided by instrument manufacturers, but these solutions are not amenable to the tandem analysis of multiple assays. This is problematic when an experiment involves more than a simple comparison between a control and treatment sample, or when many qPCR datasets are to be analyzed in a high-throughput facility. Results: We have developed HTqPCR, a package for the R statistical computing environment, to enable the processing and analysis of qPCR data across multiple conditions and replicates. Availability: HTqPCR and user documentation can be obtained through Bioconductor or at http://www.ebi.ac.uk/bertone/software. Contact: bertone\{at\}ebi.ac.uk",
	author = "Heidi Dvinge and Paul Bertone",
	doi = "10.1093/bioinformatics/btp578",
	issn = "1367-4803, 1460-2059",
	journal = "Bioinformatics",
	language = "en",
	month = dec,
	number = "24",
	pages = "3325--3326",
	pmid = "19808880",
	shorttitle = "{HTqPCR}",
	title = "{{HTqPCR}: high-throughput analysis and visualization of quantitative real-time {PCR} data in {R}}",
	url = "http://bioinformatics.oxfordjournals.org/content/25/24/3325",
	urldate = "2017-01-03",
	volume = "25",
	year = "2009"
}

@article{ronde_practical_2017,
	abstract = "Since numerous miRNAs have been shown to be present in circulation, these so-called circulating miRNAs have emerged as potential biomarkers for disease. However, results of qPCR studies on circulating miRNA biomarkers vary greatly and many experiments cannot be reproduced. Missing data in qPCR experiments often occur due to off-target amplification, nonanalyzable qPCR curves and discordance between replicates. The low concentration of most miRNAs leads to most, but not all missing data. Therefore, failure to distinguish between missing data due to a low concentration and missing data due to randomly occurring technical errors partly explains the variation within and between otherwise similar studies. Based on qPCR kinetics, an analysis pipeline was developed to distinguish missing data due to technical errors from missing data due to a low concentration of the miRNA-equivalent cDNA in the PCR reaction. Furthermore, this pipeline incorporates a method to statistically decide whether concentrations from replicates are sufficiently concordant, which improves stability of results and avoids unnecessary data loss. By going through the pipeline's steps, the result of each measurement is categorized as ``valid, invalid, or undetectable.'' Together with a set of imputation rules, the pipeline leads to more robust and reproducible data as was confirmed experimentally. Using two validation approaches, in two cohorts totaling 2214 heart failure patients, we showed that this pipeline increases both the accuracy and precision of qPCR measurements. In conclusion, this statistical data handling pipeline improves the performance of qPCR studies on low-expressed targets such as circulating miRNAs.",
	author = "Maurice W. J. de Ronde and Jan M. Ruijter and David Lanfear and Antoni Bayes-Genis and Maayke G. M. Kok and Esther E. Creemers and Yigal M. Pinto and Sara-Joan Pinto-Sietsma",
	doi = "10.1261/rna.059063.116",
	issn = "1355-8382, 1469-9001",
	journal = "RNA",
	keywords = "Data analysis; MicroRNA; qPCR",
	language = "en",
	month = may,
	number = "5",
	pages = "811--821",
	pmid = "28202710",
	title = "{Practical data handling pipeline improves performance of {qPCR}-based circulating {miRNA} measurements}",
	url = "http://rnajournal.cshlp.org/content/23/5/811",
	urldate = "2017-06-14",
	volume = "23",
	year = "2017"
}

@article{mallona_pcrefficiency:_2011,
	abstract = "Relative calculation of differential gene expression in quantitative PCR reactions requires comparison between amplification experiments that include reference genes and genes under study. Ignoring the differences between their efficiencies may lead to miscalculation of gene expression even with the same starting amount of template. Although there are several tools performing PCR primer design, there is no tool available that predicts PCR efficiency for a given amplicon and primer pair.",
	author = "Izaskun Mallona and Julia Weiss and Marcos Egea-Cortines",
	doi = "10.1186/1471-2105-12-404",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	pages = "404",
	shorttitle = "{pcrEfficiency}",
	title = "{{pcrEfficiency}: a {Web} tool for {PCR} amplification efficiency prediction}",
	urldate = "2016-09-21",
	volume = "12",
	year = "2011"
}

@article{bustin_reproducibility_2014,
	abstract = "There is increasing concern about the reliability of biomedical research, with recent articles suggesting that up to 85\% of research funding is wasted. This article argues that an important reason for this is the inappropriate use of molecular techniques, particularly in the field of RNA biomarkers, coupled with a tendency to exaggerate the importance of research findings.",
	author = "Stephen A. Bustin",
	doi = "10.1016/j.bdq.2015.01.002",
	issn = "2214-7535",
	journal = "Biomolecular Detection and Quantification",
	keywords = "Biomedicine; Cancer; Microarrays; Next generation sequencing; qPCR; Reproducibility",
	month = dec,
	pages = "35--42",
	shorttitle = "The reproducibility of biomedical research",
	title = "{The reproducibility of biomedical research: {Sleepers} awake!}",
	url = "http://www.sciencedirect.com/science/article/pii/S2214753515000030",
	urldate = "2016-10-05",
	volume = "2",
	year = "2014"
}

@article{bustin_continuing_2017,
	abstract = "Attendance at this year{\rq}s European Calcified Tissue Society{\rq}s (ECTS) Congress reveals that the methods used to obtain qPCR results continue to be significantly flawed and that and their reporting remain inadequate.",
	author = "Stephen Bustin",
	doi = "10.1016/j.bdq.2017.05.001",
	issn = "2214-7535",
	journal = "Biomolecular Detection and Quantification",
	keywords = "Bone; Expression profiling; qPCR; Reverse Transcription; RNA",
	month = jun,
	pages = "7--9",
	title = "{The continuing problem of poor transparency of reporting and use of inappropriate methods for {RT}-{qPCR}}",
	url = "http://www.sciencedirect.com/science/article/pii/S2214753517302000",
	urldate = "2017-08-11",
	volume = "12",
	year = "2017"
}

@article{wilson_good_2016,
	abstract = "Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.",
	author = "Greg Wilson and Jennifer Bryan and Karen Cranston and Justin Kitzes and Lex Nederbragt and Tracy K. Teal",
	doi = "10.1371/journal.pcbi.1005510",
	issn = "1553-7358",
	journal = "PLOS Computational Biology",
	keywords = "Reproducibility; Data management; Data processing; Computer software; Control systems; Programming languages; Software tools; Source code",
	month = jun,
	number = "6",
	pages = "e1005510",
	title = "{Good enough practices in scientific computing}",
	url = "http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510",
	urldate = "2017-12-20",
	volume = "13",
	year = "2017"
}

@article{todorov_object-oriented_2009,
	author = "Valentin Todorov and Peter Filzmoser",
	issn = "1548-7660",
	journal = "Journal of Statistical Software",
	language = "en",
	number = "3",
	title = "{An {Object}-{Oriented} {Framework} for {Robust} {Multivariate} {Analysis}}",
	url = "http://www.jstatsoft.org/v32/i03/",
	urldate = "2017-09-21",
	volume = "32",
	year = "2009"
}

@article{kuhn_building_2008,
	author = "Max Kuhn",
	issn = "1548-7660",
	journal = "Journal of Statistical Software",
	language = "en",
	number = "5",
	title = "{Building {Predictive} {Models} in {R} {Using} the caret {Package}}",
	url = "http://www.jstatsoft.org/v28/i05/",
	urldate = "2017-09-30",
	volume = "28",
	year = "2008"
}

@article{spiess_highly_2008,
	abstract = "Fitting four-parameter sigmoidal models is one of the methods established in the analysis of quantitative real-time PCR (qPCR) data. We had observed that these models are not optimal in the fitting outcome due to the inherent constraint of symmetry around the point of inflection. Thus, we found it necessary to employ a mathematical algorithm that circumvents this problem and which utilizes an additional parameter for accommodating asymmetrical structures in sigmoidal qPCR data. PMID: 18445269",
	author = "Andrej-Nikolai Spiess and Caroline Feig and Christian Ritz",
	copyright = "2008 Spiess et al; licensee BioMed Central Ltd.",
	doi = "10.1186/1471-2105-9-221",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	language = "en",
	month = apr,
	number = "1",
	pages = "221",
	pmid = "18445269",
	title = "{Highly accurate sigmoidal fitting of real-time {PCR} data by introducing a parameter for asymmetry}",
	url = "http://www.biomedcentral.com/1471-2105/9/221/abstract",
	urldate = "2014-07-01",
	volume = "9",
	year = "2008"
}

@inproceedings{gunay_machine_2016,
	author = "Melih Gunay and Evgin Goceri and Rajarajeswari Balasubramaniyan",
	booktitle = "{Machine {Learning} and {Applications} ({ICMLA}), 2016 15th {IEEE} {International} {Conference} on Machine Learning and Applications (ICMLA)}",
	doi = "10.1109/ICMLA.2016.0103",
	pages = "588--592",
	publisher = "IEEE",
	title = "{Machine {Learning} for {Optimum} {CT}-{Prediction} for {qPCR}}",
	url = "http://ieeexplore.ieee.org/abstract/document/7838207/",
	urldate = "2017-10-03",
	year = "2016"
}

@article{sauer_differentiation_2016,
	author = "Eva Sauer and Ann-Kathrin Reinke and Cornelius Courts",
	doi = "10.1016/j.fsigen.2016.01.018",
	issn = "18724973",
	journal = "Forensic Science International: Genetics",
	language = "en",
	month = may,
	pages = "89--99",
	title = "{Differentiation of five body fluids from forensic samples by expression analysis of four {microRNAs} using quantitative {PCR}}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1872497316300187",
	urldate = "2016-08-16",
	volume = "22",
	year = "2016"
}

@article{martins_dna_2015,
	author = "C. Martins and G. Lima and Mr. Carvalho and L. Cain{\'e} and Mj. Porto",
	doi = "10.1016/j.fsigss.2015.09.215",
	issn = "18751768",
	journal = "Forensic Science International: Genetics Supplement Series",
	language = "en",
	month = dec,
	pages = "e545--e546",
	title = "{{DNA} quantification by real-time {PCR} in different forensic samples}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1875176815301335",
	urldate = "2016-12-22",
	volume = "5",
	year = "2015"
}

@article{baebler_quantgenius:_2017,
	author = "\v{S}pela Baebler and Miha Svalina and Marko Petek and Katja Stare and Ana Rotter and Maru\v{s}a Pompe-Novak and Kristina Gruden",
	doi = "10.1186/s12859-017-1688-7",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	language = "en",
	month = dec,
	number = "1",
	shorttitle = "{quantGenius}",
	title = "{{quantGenius}: implementation of a decision support system for {qPCR}-based gene quantification}",
	urldate = "2017-09-26",
	volume = "18",
	year = "2017"
}

@article{barratt_improving_2002,
	author = "Kevin Barratt and John F. Mackay",
	doi = "10.1128/JCM.40.4.1571-1572.2002",
	issn = "0095-1137, 1098-660X",
	journal = "Journal of Clinical Microbiology",
	language = "en",
	month = apr,
	number = "4",
	pages = "1571--1572",
	pmid = "11923402",
	title = "{Improving {Real}-{Time} {PCR} {Genotyping} {Assays} by {Asymmetric} {Amplification}}",
	url = "http://jcm.asm.org/content/40/4/1571",
	urldate = "2017-08-06",
	volume = "40",
	year = "2002"
}

@article{brenner_variation_1997,
	author = "Hermann Brenner and Olaf Gefeller",
	journal = "Statistics in medicine",
	number = "9",
	pages = "981--991",
	title = "{Variation of sensitivity, specificity, likelihood ratios and predictive values with disease prevalence}",
	url = "http://www.floppybunny.org/robin/web/virtualclassroom/stats/basics/articles/odds_risks/odds_sensitivity)likelihood_ratios_validity_brenner_1997.pdf",
	urldate = "2017-09-30",
	volume = "16",
	year = "1997"
}

@article{handt_digitale_2015,
	author = "Gordon Handt and Mario Menschikowski and Werner Lehmann and Peter Schierack and Stefan R{\"o}diger",
	doi = "10.1007/s12268-015-0610-y",
	issn = "0947-0867, 1868-6249",
	journal = "BIOspektrum",
	language = "de",
	month = sep,
	number = "5",
	pages = "507--510",
	title = "{Digitale {PCR} in der {Labordiagnostik}}",
	urldate = "2017-06-18",
	volume = "21",
	year = "2015"
}

@article{Ritz2008,
	abstract = "Summary: The qpcR library is an add-on to the free R statistical environment performing sigmoidal model selection in real-time quantitative polymerase chain reaction (PCR) data analysis. Additionally, the package implements the most commonly used algorithms for real-time PCR data analysis and is capable of extensive statistical comparison for the selection and evaluation of the different models based on several measures of goodness of fit. Availability: www.dr-spiess.de/qpcR.html. Contact: a.spiess@uke.uni-hamburg.de Supplementary Information: Statistical evaluations of the implemented methods can be found at www.dr-spiess.de under {\lq}Supplemental Data{\rq}.",
	author = "Christian Ritz and Andrej-Nikolai Spiess",
	doi = "10.1093/bioinformatics/btn227",
	issn = "1367-4803, 1460-2059",
	journal = "Bioinformatics",
	language = "en",
	month = jul,
	number = "13",
	pages = "1549--1551",
	pmid = "18482995",
	shorttitle = "{qpcR}",
	title = "{{qpcR}: an {R} package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis}",
	url = "http://bioinformatics.oxfordjournals.org/content/24/13/1549",
	urldate = "2014-04-07",
	volume = "24",
	year = "2008"
}

@article{roediger_enabling_2017,
	abstract = "Motivation: Reproducibility, a cornerstone of research, requires defined data formats, which include the setup and output of experiments. The real-time PCR data markup language (RDML) is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines. Despite the popularity of the RDML format for analysis of quantitative PCR data, handling of RDML files is not yet widely supported in all PCR curve analysis softwares.Results: This study describes the open-source RDML package for the statistical computing language R. RDML is compatible with RDML versions â‰¤ 1.2 and provides functionality to (i) import RDML data; (ii) extract sample information (e.g. targets and concentration); (iii) transform data to various formats of the R environment; (iv) generate human-readable run summaries; and (v) to create RDML files from user data. In addition, RDML offers a graphical user interface to read, edit and create RDML files.Availability and implementation:https://cran.r-project.org/package=RDML. rdmlEdit server http://shtest.evrogen.net/rdmlEdit/. Documentation: http://kablag.github.io/RDML/.Contact:k.blag@yandex.ruSupplementary information:Supplementary data are available at Bioinformatics online.",
	author = "Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Andrej-Nikolai Spiess and Konstantin Blagodatskikh",
	doi = "10.1093/bioinformatics/btx528",
	journal = "Bioinformatics",
	month = aug,
	shorttitle = "Enabling reproducible real-time quantitative {PCR} research",
	title = "{Enabling reproducible real-time quantitative {PCR} research: the {RDML} package}",
	urldate = "2017-09-09",
	year = "2017"
}

@article{ruijter_evaluation_2013,
	author = "Jan M. Ruijter and Michael W. Pfaffl and Sheng Zhao and Andrej N. Spiess and Gregory Boggy and Jochen Blom and Robert G. Rutledge and Davide Sisti and Antoon Lievens and Katleen {De Preter} and Stefaan Derveaux and Jan Hellemans and Jo Vandesompele",
	doi = "10.1016/j.ymeth.2012.08.011",
	issn = "10462023",
	journal = "Methods",
	keywords = "Benchmark; Bias; Precision; qPCR curve analysis; Resolution; Transcriptional biomarker",
	language = "en",
	month = jan,
	number = "1",
	pages = "32--46",
	shorttitle = "Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery",
	title = "{Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery: {Bias}, resolution, precision, and implications}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1046202312002290",
	urldate = "2016-10-05",
	volume = "59",
	year = "2013"
}

@article{spiess_system-specific_2016,
	author = "Andrej-Nikolai Spiess and Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Thomas Volksdorf and Joel Tellinghuisen",
	doi = "10.1038/srep38951",
	issn = "2045-2322",
	journal = "Scientific Reports",
	month = dec,
	pages = "38951",
	title = "{System-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation}",
	url = "http://www.nature.com/articles/srep38951",
	urldate = "2016-12-14",
	volume = "6",
	year = "2016"
}

@manual{pracma,
	author = "Hans Werner Borchers",
	note = "R package version 2.0.7",
	title = "{{pracma}: Practical Numerical Math Functions}",
	url = "https://CRAN.R-project.org/package=pracma",
	year = "2017"
}

@inproceedings{charpiat_shape_2003,
	author = "Guillaume Charpiat and Olivier Faugeras and Renaud Keriven",
	booktitle = "{Image {Processing}, 2003. {ICIP} 2003. {Proceedings}. 2003 {International} {Conference} on}",
	pages = "II--627",
	publisher = "IEEE",
	title = "{Shape metrics, warping and statistics}",
	url = "http://ieeexplore.ieee.org/abstract/document/1246758/",
	urldate = "2017-07-30",
	volume = "2",
	year = "2003"
}

@article{porzelius_easier_2009,
	author = "Christine Porzelius and Harald Binder Jochen Knaus and Guido Schwarzer",
	journal = "The R Journal",
	month = jun,
	number = "1",
	pages = "54--59",
	title = "{Easier {Parallel} {Computing} in {R} with snowfall and {sfCluster}}",
	url = "http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Knaus+et+al.pdf",
	volume = "1",
	year = "2009"
}

@article{schmidberger_2009,
	author = "Markus Schmidberger and Martin Morgan and Dirk Eddelbuettel and Hao Yu and Luke Tierney and Ulrich Mansmann",
	journal = "Journal of Statistical Software",
	number = "1",
	title = "{State-of-the-art in {Parallel} {Computing} with {R}}",
	volume = "47",
	year = "2009"
}

@article{eddelbuettel_cran_2017,
	author = "Dirk Eddelbuettel",
	month = sep,
	shorttitle = "{CRAN} {Task} {View}",
	title = "{{CRAN} {Task} {View}: {High}-{Performance} and {Parallel} {Computing} with {R}}",
	url = "https://CRAN.R-project.org/view=HighPerformanceComputing",
	urldate = "2017-11-03",
	year = "2017"
}

@article{quinlan_induction_1986,
	author = "J. Ross Quinlan",
	journal = "Machine learning",
	number = "1",
	pages = "81--106",
	title = "{Induction of decision trees}",
	url = "http://link.springer.com/article/10.1007/BF00116251",
	urldate = "2017-07-25",
	volume = "1",
	year = "1986"
}

@article{luan_signal-detection_2011,
	author = "Shenghua Luan and Lael J. Schooler and Gerd Gigerenzer",
	doi = "10.1037/a0022684",
	issn = "1939-1471, 0033-295X",
	journal = "Psychological Review",
	language = "en",
	number = "2",
	pages = "316--338",
	title = "{A signal-detection analysis of fast-and-frugal trees.}",
	url = "http://doi.apa.org/getdoi.cfm?doi=10.1037/a0022684",
	urldate = "2017-11-10",
	volume = "118",
	year = "2011"
}

@article{richards_flexible_1959,
	abstract = "The application of an extended form of von Bertalanffy's growth function to plant data is considered; the equation has considerable flexibility, but is used only to supply an empirical fit. In order to aid the biological analysis of such growth data as are capable of representation by the function, general rate parameters are deduced which are related in a simple manner to its constants.",
	author = "F. J. Richards",
	doi = "10.1093/jxb/10.2.290",
	issn = "0022-0957",
	journal = "Journal of Experimental Botany",
	month = jun,
	number = "2",
	pages = "290--301",
	title = "{A {Flexible} {Growth} {Function} for {Empirical} {Use}}",
	url = "https://academic.oup.com/jxb/article/10/2/290/528209",
	urldate = "2017-12-30",
	volume = "10",
	year = "1959"
}

@article{lanubile_collaboration_2010,
	abstract = "Software engineering involves people collaborating to develop better software. Collaboration is challenging, especially across time zones and without face-to-face meetings. We therefore use collaboration tools all along the product life cycle to let us work together, stay together, and achieve results together. This article summarizes experiences and trends chosen from recent IEEE International Conference on Global Software Engineering (IGSCE) conferences.",
	author = "F. Lanubile and C. Ebert and R. Prikladnicki and A. Vizca{\'i}no",
	doi = "10.1109/MS.2010.39",
	issn = "0740-7459",
	journal = "IEEE Software",
	keywords = "collaboration; collaboration tools; Collaborative software; Collaborative tools; Collaborative work; global software development; global software engineering; groupware; IEEE international conference; International collaboration; Meetings; product life cycle; product life cycle management; software engineering; Software engineering",
	month = mar,
	number = "2",
	pages = "52--55",
	title = "{Collaboration {Tools} for {Global} {Software} {Engineering}}",
	volume = "27",
	year = "2010"
}

@article{knuth_literate_1984,
	abstract = "The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.",
	author = "D. E. Knuth",
	doi = "10.1093/comjnl/27.2.97",
	issn = "0010-4620, 1460-2067",
	journal = "The Computer Journal",
	language = "en",
	month = jan,
	number = "2",
	pages = "97--111",
	title = "{Literate {Programming}}",
	url = "http://comjnl.oxfordjournals.org/content/27/2/97",
	urldate = "2015-10-26",
	volume = "27",
	year = "1984"
}

@article{Killick_2014,
	author = "Rebecca Killick and Idris A. Eckley",
	journal = "Journal of Statistical Software",
	number = "3",
	pages = "1--19",
	title = "{{changepoint}: An {R} Package for Changepoint Analysis}",
	url = "http://www.jstatsoft.org/v58/i03/",
	volume = "58",
	year = "2014"
}

@article{erdman_bcp:_2007,
	author = "Chandra Erdman and John W. Emerson and {others}",
	journal = "Journal of Statistical Software",
	number = "3",
	pages = "1--13",
	shorttitle = "bcp",
	title = "{{bcp}: an {R} package for performing a {Bayesian} analysis of change point problems}",
	url = "https://www.researchgate.net/profile/Chandra_Erdman/publication/26538600_bcp_An_R_Package_for_Performing_a_Bayesian_Analysis_of_Change_Point_Problems/links/56dee56608aec8c022cf2fd2.pdf",
	urldate = "2017-08-13",
	volume = "23",
	year = "2007"
}

@article{scott_cluster_1974,
	author = "A. J. Scott and M. Knott",
	doi = "10.2307/2529204",
	issn = "0006341X",
	journal = "Biometrics",
	month = sep,
	number = "3",
	pages = "507",
	title = "{A {Cluster} {Analysis} {Method} for {Grouping} {Means} in the {Analysis} of {Variance}}",
	url = "http://www.jstor.org/stable/2529204?origin=crossref",
	urldate = "2017-08-07",
	volume = "30",
	year = "1974"
}

@article{Baaaath_2012,
	author = "Rasmus B{\aa}{\aa}th",
	journal = "{The R Journal}",
	month = dec,
	number = "2",
	pages = "74--75",
	title = "{The State of Naming Conventions in {R}}",
	url = "http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf",
	volume = "4",
	year = "2012"
}

@manual{Chang_R6,
	author = "Winston Chang",
	note = "R package version 2.1.0",
	title = "{R6: Classes with Reference Semantics}",
	url = "http://CRAN.R-project.org/package=R6",
	year = "2015"
}

@manual{FFTrees_package,
	author = "Nathaniel Phillips and Hansjoerg Neth and Jan Woike and Wolfgang Gaissmaer",
	note = "R package version 1.3.5",
	title = "{FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees}",
	url = "https://CRAN.R-project.org/package=FFTrees",
	year = "2017"
}

@article{Febrero_Bande_2012,
	author = "Manuel Febrero-Bande and Manuel {Oviedo de la Fuente}",
	journal = "Journal of Statistical Software",
	number = "4",
	pages = "1--28",
	shorttitle = "Statistical computing in functional data analysis",
	title = "{Statistical Computing in Functional Data Analysis: {The} {R} Package {fda.usc}}",
	url = "http://www.jstatsoft.org/v51/i04/",
	volume = "51",
	year = "2012"
}

@article{Fischer_HDF5,
	author = "Bernd Fischer and Gregoire Pau",
	journal = "R package version 2.10.0",
	title = "{{rhdf5}: {HDF5} interface to {R}}",
	url = "http://www.bioconductor.org/packages/release/bioc/html/rhdf5.html",
	year = "2015"
}

@article{Horsman2007,
	author = "Katie M. Horsman and Joan M. Bienvenue and Kiev R. Blasier and James P. Landers",
	doi = "10.1111/j.1556-4029.2007.00468.x",
	issn = "0022-1198, 1556-4029",
	journal = "Journal of Forensic Sciences",
	language = "en",
	month = jul,
	number = "4",
	pages = "784--799",
	shorttitle = "Forensic {DNA} {Analysis} on {Microfluidic} {Devices}",
	title = "{Forensic {DNA} {Analysis} on {Microfluidic} {Devices}: {A} {Review}}",
	url = "http://doi.wiley.com/10.1111/j.1556-4029.2007.00468.x",
	urldate = "2016-09-10",
	volume = "52",
	year = "2007"
}

@manual{Lang_XML,
	author = "Duncan Temple Lang and the CRAN Team",
	note = "R package version 3.98-1.3",
	title = "{{XML}: Tools for Parsing and Generating {XML} Within {R} and {S-Plus}}",
	url = "http://CRAN.R-project.org/package=XML",
	year = "2015"
}

@article{Leeper_2014,
	author = "Thomas J. Leeper",
	journal = "The R Journal",
	number = "1",
	pages = "151--158",
	title = "{Archiving Reproducible Research and Dataverse with {R}}",
	url = "http://journal.r-project.org/archive/2014-1/leeper.pdf",
	volume = "6",
	year = "2014"
}

@manual{Mersmann_2014_microbenchmark,
	author = "Mersmann Olaf and Beleites Claudia and Hurling Rainer and Friedman Ari",
	note = "R package version 1.4-2",
	title = "{{microbenchmark}: Accurate Timing Functions}",
	url = "http://CRAN.R-project.org/package=microbenchmark",
	year = "2014"
}

@manual{RDCT2010c,
	address = "Vienna, Austria",
	author = "{{R} Development Core Team}",
	note = "{ISBN} 3-900051-10-0",
	organization = "{R} Foundation for Statistical Computing",
	title = "{{R} Data {Import/Export}}",
	url = "http://www.R-project.org/",
	year = "2012"
}

@manual{R_language,
	address = "Vienna, Austria",
	author = "{R Core Team}",
	organization = "R Foundation for Statistical Computing",
	title = "{R: A Language and Environment for Statistical Computing}",
	url = "https://www.R-project.org/",
	year = "2017"
}

@manual{Radford_2014_microbenchmark,
	author = "Neal Radford",
	note = "https://web.archive.org/web/20140823221902/http://www.r-bloggers.com/inaccurate-results-from-microbenchmark/",
	title = "{Inaccurate results from microbenchmark}",
	url = "https://web.archive.org/web/20140823221902/http://www.r-bloggers.com/inaccurate-results-from-microbenchmark/",
	year = "2014"
}

@manual{Ren_rlist,
	author = "Kun Ren",
	note = "R package version 0.4.2.3",
	title = "{{rlist}: A Toolbox for Non-Tabular Data Manipulation}",
	url = "http://CRAN.R-project.org/package=rlist",
	year = "2015"
}

@manual{Schutten_2014_ods,
	author = "Gerrit-Jan Schutten",
	note = "R package version 1.4",
	title = "{{readODS}: Read {ODS} files and puts them into data frames}",
	url = "http://CRAN.R-project.org/package=readODS",
	year = "2014"
}

@article{Tierney2017,
	author = "Nicholas Tierney",
	journal = "{The Journal of Open Source Software}",
	month = "aug",
	number = "16",
	publisher = "The Open Journal",
	title = "{{visdat}: Visualising Whole Data Frames}",
	volume = "2",
	year = "2017"
}

@article{Valero_2012,
	accepted = "2012-06-03",
	author = "Pedro M. Valero-Mora and Ruben Ledesma",
	bibdate = "2012-06-03",
	coden = "JSSOBK",
	day = "30",
	issn = "1548-7660",
	journal = "Journal of Statistical Software",
	number = "1",
	pages = "1--8",
	submitted = "2012-06-03",
	title = "{Graphical User Interfaces for {R}}",
	url = "http://www.jstatsoft.org/v49/i01",
	volume = "49",
	year = "2012"
}

@manual{Warnes_2015_gdata,
	author = "Gregory R. Warnes and Ben Bolker and Gregor Gorjanc and Gabor Grothendieck and Ales Korosec and Thomas Lumley and Don MacQueen and Arni Magnusson and Jim Rogers and {others}",
	note = "R package version 2.17.0",
	title = "{{gdata}: Various {R} Programming Tools for Data Manipulation}",
	url = "http://CRAN.R-project.org/package=gdata",
	year = "2015"
}

@manual{Wickham_Francois_dplyr,
	author = "Hadley Wickham and Romain Francois",
	note = "R package version 0.4.2",
	title = "{{dplyr}: A Grammar of Data Manipulation}",
	url = "http://CRAN.R-project.org/package=dplyr",
	year = "2015"
}

@manual{Wickham_assertthat,
	author = "Hadley Wickham",
	note = "R package version 0.1",
	title = "{{assertthat}: Easy pre and post assertions.}",
	url = "http://CRAN.R-project.org/package=assertthat",
	year = "2013"
}

@article{Wickham_plyr,
	author = "Hadley Wickham",
	journal = "Journal of Statistical Software",
	number = "1",
	pages = "1--29",
	title = "{The Split-Apply-Combine Strategy for Data Analysis}",
	url = "http://www.jstatsoft.org/v40/i01/",
	volume = "40",
	year = "2011"
}

@manual{Wickham_tidyr,
	author = "Hadley Wickham",
	note = "R package version 0.2.0",
	title = "{{tidyr}: Easily Tidy Data with spread() and gather() Functions.}",
	url = "http://CRAN.R-project.org/package=tidyr",
	year = "2014"
}

@article{achard_xml_2001,
	author = "Fr{\'e}d{\'e}ric Achard and Guy Vaysseix and Emmanuel Barillot",
	doi = "10.1093/bioinformatics/17.2.115",
	issn = "1367-4803, 1460-2059",
	journal = "{Bioinformatics}",
	language = "en",
	number = "2",
	pages = "115--125",
	pmid = "11238067",
	title = "{{XML}, bioinformatics and data integration}",
	url = "http://bioinformatics.oxfordjournals.org/content/17/2/115",
	volume = "17",
	year = "2001"
}

@article{alonso_real-time_2007,
	author = "Antonio Alonso and Oscar Garc{\'i}a",
	journal = "Molecular Forensics",
	pages = "59",
	title = "{Real-time quantitative {PCR} in forensic science}",
	url = "https://books.google.com/books?hl=en&lr=&id=TuZE41OlV6UC&oi=fnd&pg=PA59&dq=%22limit+of+the+STR+pro%EF%AC%81ling+approaches,+was+often+not+sensitive+enough%22+%22et+al.,+2005%3B+Andr%C3%A9asson+et+al.,+2006%3B+Swango+et+al.,+2006)+have%22+%22applied+in+forensic+genetics+for+the+speci%EF%AC%81c+quanti%EF%AC%81cation+of+human%22+&ots=NPJoFjaKRx&sig=g2QRKTPUmOGxb_W95MndOlo6naI",
	urldate = "2016-12-20",
	year = "2007"
}

@article{andreasson_sensitive_2005,
	abstract = "The field of forensic genetics is growing fast and the development and optimisation of more sensitive, faster and more discriminating forensic DNA analysis methods is highly important. In this thes ...",
	author = "Hanna Andr{\'e}asson",
	language = "eng",
	shorttitle = "Sensitive {Forensic} {DNA} {Analysis}",
	title = "{Sensitive {Forensic} {DNA} {Analysis} : {Application} of {Pyrosequencing} and {Real}-time {PCR} {Quantification}}",
	url = "http://uu.diva-portal.org/smash/record.jsf?pid=diva2:166330",
	urldate = "2016-12-16",
	year = "2005"
}

@article{arlot_survey_2010,
	abstract = "Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.",
	author = "Sylvain Arlot and Alain Celisse",
	doi = "10.1214/09-SS054",
	issn = "1935-7516",
	journal = "Statistics Surveys",
	keywords = "cross-validation; leave-one-out; Model selection",
	language = "EN",
	note = "Mathematical Reviews number (MathSciNet) MR2602303, Zentralblatt MATH identifier1190.62080",
	pages = "40--79",
	title = "{A survey of cross-validation procedures for model selection}",
	url = "http://projecteuclid.org/euclid.ssu/1268143839",
	urldate = "2014-04-23",
	volume = "4",
	year = "2010"
}

@article{athamanolap_trainable_2014,
	author = "Pornpat Athamanolap and Vishwa Parekh and Stephanie I. Fraley and Vatsal Agarwal and Dong J. Shin and Michael A. Jacobs and Tza-Huei Wang and Samuel Yang",
	doi = "10.1371/journal.pone.0109094",
	editor = "John Z. Metcalfe",
	issn = "1932-6203",
	journal = "PLoS ONE",
	language = "en",
	month = oct,
	number = "10",
	pages = "e109094",
	title = "{Trainable {High} {Resolution} {Melt} {Curve} {Machine} {Learning} {Classifier} for {Large}-{Scale} {Reliable} {Genotyping} of {Sequence} {Variants}}",
	url = "http://dx.plos.org/10.1371/journal.pone.0109094",
	urldate = "2017-06-24",
	volume = "9",
	year = "2014"
}

@article{baker_quantitative_2012,
	abstract = "Adaptive technologies are helping researchers combine and organize experimental results.",
	author = "Monya Baker",
	copyright = "Â© 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.",
	doi = "10.1038/nmeth.1815",
	issn = "1548-7091",
	journal = "Nature Methods",
	number = "1",
	pages = "39--41",
	shorttitle = "Quantitative data",
	title = "{Quantitative data: learning to share}",
	url = "http://www.nature.com/nmeth/journal/v9/n1/full/nmeth.1815.html",
	urldate = "2015-08-08",
	volume = "9",
	year = "2012"
}

@article{barber_utility_2006,
	abstract = "ABSTRACT: Biological evidence has become invaluable in the crime laboratory; however, it may exist in limited quantity and/or quality. Given this, the ability to amplify total DNA obtained from evidence, in an unbiased manner, would be highly advantageous. Methods for whole genome amplification (WGA) have the potential to fulfill this role, resulting in a virtually unlimited supply of DNA. In the research presented, two WGA methods, improved primer extension preamplification and multiple displacement amplification (MDA), were tested using commercial kits. Control DNA, artificially degraded DNA, and DNA from fresh blood, aged blood, hair shafts, and aged bones underwent WGA, followed by short tandem repeat and mitochondrial DNA analysis. The methods did amplify DNA, but performed poorly on forensically relevant samples; the maximum amplicon size was reduced, and MDA often resulted in extraneous bands following polymerase chain reaction. Taken together, WGA appears to be of limited forensic utility unless the samples are of a very high quality.",
	author = "Amy L. Barber and David R. Foran",
	doi = "10.1111/j.1556-4029.2006.00262.x",
	issn = "1556-4029",
	journal = "Journal of Forensic Sciences",
	keywords = "Degraded DNA; DNA typing; forensic science; improved primer extension preamplification; mitochondrial DNA; multiple displacement amplification; short tandem repeat",
	language = "en",
	month = nov,
	number = "6",
	pages = "1344--1349",
	title = "{The {Utility} of {Whole} {Genome} {Amplification} for {Typing} {Compromised} {Forensic} {Samples}}",
	url = "http://onlinelibrary.wiley.com/doi/10.1111/j.1556-4029.2006.00262.x/abstract",
	urldate = "2016-12-03",
	volume = "51",
	year = "2006"
}

@article{beer_bestimmung_1852,
	author = "{Beer}",
	doi = "10.1002/andp.18521620505",
	issn = "1521-3889",
	journal = "Annalen der Physik",
	language = "en",
	month = jan,
	number = "5",
	pages = "78--88",
	title = "{Bestimmung der {Absorption} des rothen {Lichts} in farbigen {Fl{\"u}ssigkeiten}}",
	url = "http://onlinelibrary.wiley.com/doi/10.1002/andp.18521620505/abstract",
	urldate = "2017-12-22",
	volume = "162",
	year = "1852"
}

@article{berg_dna_2002,
	abstract = "Genes must be expressed to exert an effect, and proteins regulate such expression. One such regulatory protein, a zinc-finger protein (zinc ion is blue, protein is red), is shown bound to a control or promoter region of DNA (black). [Barnaby Hall/Photonica.]",
	author = "Jeremy M. Berg and John L. Tymoczko and Lubert Stryer",
	language = "en",
	title = "{{DNA}, {RNA}, and the {Flow} of {Genetic} {Information}}",
	url = "https://www.ncbi.nlm.nih.gov/books/NBK21171/",
	urldate = "2017-12-22",
	year = "2002"
}

@article{bianchi_forensic_2007,
	abstract = "The field of forensic science is increasingly based on biomolecular data and many European countries are establishing forensic databases to store DNA profiles of crime scenes of known offenders and apply DNA testing. The field is boosted by statistical and technological advances such as DNA microarray sequencing, TFT biosensors, machine learning algorithms, in particular Bayesian networks, which provide an effective way of evidence organization and inference. The aim of this article is to discuss the state of art potentialities of bioinformatics in forensic DNA science. We also discuss how bioinformatics will address issues related to privacy rights such as those raised from large scale integration of crime, public health and population genetic susceptibility-to-diseases databases.",
	author = "Lucia Bianchi and Pietro Li{\`o}",
	doi = "10.1093/bib/bbm006",
	issn = "1467-5463, 1477-4054",
	journal = "Briefings in Bioinformatics",
	keywords = "Bayesian networks; CODIS; DNA microarray; DNA testing; forensic science",
	language = "en",
	month = mar,
	number = "2",
	pages = "117--128",
	pmid = "17384432",
	title = "{Forensic {DNA} and bioinformatics}",
	url = "http://bib.oxfordjournals.org/content/8/2/117",
	urldate = "2016-11-01",
	volume = "8",
	year = "2007"
}

@book{bischl_mlr:_2010,
	author = "Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones",
	shorttitle = "mlr",
	title = "{{mlr}: {Machine} learning in {R}}",
	url = "http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf",
	urldate = "2017-06-25",
	year = "2010"
}

@article{boehringer_dynamic_2013,
	author = "Stefan Boehringer",
	journal = "The R Journal",
	month = dec,
	number = "2",
	pages = "88--97",
	title = "{Dynamic {Parallelization} of {R} {Functions}}",
	url = "http://journal.r-project.org/archive/2013-2/RJournal_2013-2_boehringer.pdf",
	volume = "5",
	year = "2013"
}

@article{burdukiewicz_methods_2016,
	abstract = "The estimated mean copy per partition (Î») is the essential information from a digital PCR (dPCR) experiment because Î» can be used to calculate the target concentration in a sample. However, little information is available how to statistically compare dPCR runs of multiple runs or reduplicates. The comparison of Î» values from several runs is a multiple comparison problem, which can be solved using the binary structure of dPCR data. We propose and evaluate two novel methods based on Generalized Linear Models (GLM) and Multiple Ratio Tests (MRT) for comparison of digital PCR experiments. We enriched our MRT framework with computation of simultaneous confidence intervals suitable for comparing multiple dPCR runs. The evaluation of both statistical methods support that MRT is faster and more robust for dPCR experiments performed in large scale. Our theoretical results were confirmed by the analysis of dPCR measurements of dilution series. Both methods were implemented in the dpcR package (v. 0.2) for the open source R statistical computing environment.",
	author = "Micha{\l} Burdukiewicz and Stefan R{\"o}diger and Piotr Sobczyk and Mario Menschikowski and Peter Schierack and Pawe{\l} Mackiewicz",
	doi = "10.1016/j.bdq.2016.06.004",
	issn = "2214-7535",
	journal = "Biomolecular Detection and Quantification",
	keywords = "Digital PCR; generalized linear models; dPCR; GLM; Multiple comparison",
	language = "eng",
	month = sep,
	pages = "14--19",
	pmid = "27551672",
	title = "{Methods for comparing multiple digital {PCR} experiments}",
	volume = "9",
	year = "2016"
}

@article{bustin_miqe_2009,
	abstract = "Background: Currently, a lack of consensus exists on how best to perform and interpret quantitative real-time {PCR} ({qPCR}) experiments. The problem is exacerbated by a lack of sufficient experimental detail in many publications, which impedes a reader{\rq}s ability to evaluate critically the quality of the results presented or to repeat the experiments. Content: The Minimum Information for Publication of Quantitative Real-Time {PCR} Experiments ({MIQE}) guidelines target the reliability of results to help ensure the integrity of the scientific literature, promote consistency between laboratories, and increase experimental transparency. {MIQE} is a set of guidelines that describe the minimum information necessary for evaluating {qPCR} experiments. Included is a checklist to accompany the initial submission of a manuscript to the publisher. By providing all relevant experimental conditions and assay characteristics, reviewers can assess the validity of the protocols used. Full disclosure of all reagents, sequences, and analysis methods is necessary to enable other investigators to reproduce results. {MIQE} details should be published either in abbreviated form or as an online supplement. Summary: Following these guidelines will encourage better experimental practice, allowing more reliable and unequivocal interpretation of {qPCR} results.",
	author = "Stephen A. Bustin and Vladimir Benes and Jeremy A. Garson and Jan Hellemans and Jim Huggett and Mikael Kubista and Reinhold Mueller and Tania Nolan and Michael W. Pfaffl and Gregory L. Shipley and Jo Vandesompele and Carl T. Wittwer",
	date = "2009-01-04",
	doi = "10.1373/clinchem.2008.112797",
	issn = "0009-9147, 1530-8561",
	journal = "Clinical Chemistry",
	journaltitle = "Clinical Chemistry",
	langid = "english",
	number = "4",
	pages = "611--622",
	pmid = "19246619",
	shortjournal = "Clinical Chemistry",
	shorttitle = "The {MIQE} Guidelines",
	title = "{The {MIQE} Guidelines: Minimum Information for Publication of Quantitative Real-Time {PCR} Experiments}",
	url = "http://www.clinchem.org/content/55/4/611",
	urldate = "2014-09-11",
	volume = "55",
	year = "2009"
}

@inproceedings{choi_study_2011,
	author = "Y Choi and A S Ralhan and S Ko",
	doi = "10.1109/ICISA.2011.5772404",
	isbn = "978-1-4244-9222-0",
	month = apr,
	pages = "1--8",
	publisher = "IEEE",
	title = "{A {Study} on {Machine} {Learning} {Algorithms} for {Fall} {Detection} and {Movement} {Classification}}",
	url = "http://ieeexplore.ieee.org/document/5772404/",
	urldate = "2017-06-30",
	year = "2011"
}

@book{cook_interactive_2007,
	abstract = "This book is about using interactive and dynamic plots on a computer screen as part of data exploration and modeling, both alone and as a partner with static graphics and non-graphical computational methods. The area of inter- active and dynamic data visualization emerged within statistics as part of research on exploratory data analysis in the late 1960s, and it remains an active subject of research today, as its use in practice continues to grow. It now makes substantial contributions within computer science as well, as part of the growing fields of information visualization and data mining, especially visual data mining.",
	address = "New York",
	author = "Dianne Cook and Deborah F. Swayne",
	edition = "2007 edition",
	isbn = "978-0-387-71761-6",
	language = "English",
	month = dec,
	note = "DOI:10.1007/978-0-387-71762-3",
	publisher = "Springer",
	series = "{1}",
	shorttitle = "Interactive and {Dynamic} {Graphics} for {Data} {Analysis}",
	title = "{Interactive and {Dynamic} {Graphics} for {Data} {Analysis}: {With} {R} and {GGobi}}",
	url = "http://www.springer.com/us/book/9780387717616",
	year = "2007"
}

@article{curran_statistics_2009,
	abstract = "Statistical thinking and computation are taking an increasing role in the field of forensic science. Heavy emphasis on Bayesian reasoning and logic over the last 20 years has revolutionized the interpretation of DNA evidence, glass evidence, and fingerprint evidence. This revolution has led to an increased demand for statistical software that makes the methodology accessible and usable. Interpretation of evidence is one part of forensic science where statistics is making a contribution. There are strong efforts, especially in the field of DNA, being made toward developing probabilistic expert systems which can aid investigators through intelligence-led policing. This paper will attempt to review the advances that have been made in the field of forensic science through statistical methodology. Copyright Â© 2009 John Wiley \& Sons, Inc. For further resources related to this article, please visit the WIREs website.",
	author = "James M. Curran",
	doi = "10.1002/wics.33",
	issn = "1939-0068",
	journal = "Wiley Interdisciplinary Reviews: Computational Statistics",
	language = "en",
	month = sep,
	number = "2",
	pages = "141--156",
	title = "{Statistics in forensic science}",
	url = "http://onlinelibrary.wiley.com/doi/10.1002/wics.33/abstract",
	urldate = "2016-08-15",
	volume = "1",
	year = "2009"
}

@manual{dataMaid,
	author = "Anne Helby Petersen and Claus Thorn Ekstr{\o}m",
	note = "R package version 0.9.2",
	title = "{dataMaid: A Suite of Checks for Identification of Potential Errors in a Data Frame as Part of the Data Cleaning Process}",
	url = "https://CRAN.R-project.org/package=dataMaid",
	year = "2017"
}

@manual{dragulescu_xlsx_2014,
	abstract = "Provide R functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003 file formats.",
	author = "Adrian A. Dragulescu",
	copyright = "GPL-3",
	shorttitle = "xlsx",
	title = "{xlsx: {Read}, write, format {Excel} 2007 and {Excel} 97/2000/{XP}/2003 files}",
	url = "https://cran.r-project.org/web/packages/xlsx/index.html",
	urldate = "2015-08-13",
	year = "2014"
}

@article{feuer_lemming:_2015,
	abstract = "Background Gene expression analysis is an essential part of biological and medical investigations. Quantitative real-time PCR (qPCR) is characterized with excellent sensitivity, dynamic range, reproducibility and is still regarded to be the gold standard for quantifying transcripts abundance. Parallelization of qPCR such as by microfluidic Taqman Fluidigm Biomark Platform enables evaluation of multiple transcripts in samples treated under various conditions. Despite advanced technologies, correct evaluation of the measurements remains challenging. Most widely used methods for evaluating or calculating gene expression data include geNorm and Î”Î” C t , respectively. They rely on one or several stable reference genes (RGs) for normalization, thus potentially causing biased results. We therefore applied multivariable regression with a tailored error model to overcome the necessity of stable RGs. Results We developed a RG independent data normalization approach based on a tailored l inear e rror m odel for parallel qPCR data, called LEMming. It uses the assumption that the mean C t values within samples of similarly treated groups are equal. Performance of LEMming was evaluated in three data sets with different stability patterns of RGs and compared to the results of geNorm normalization. Data set 1 showed that both methods gave similar results if stable RGs are available. Data set 2 included RGs which are stable according to geNorm criteria, but became differentially expressed in normalized data evaluated by a t-test. geNorm -normalized data showed an effect of a shifted mean per gene per condition whereas LEMming-normalized data did not. Comparing the decrease of standard deviation from raw data to geNorm and to LEMming, the latter was superior. In data set 3 according to geNorm calculated average expression stability and pairwise variation, stable RGs were available, but t-tests of raw data contradicted this. Normalization with RGs resulted in distorted data contradicting literature, while LEMming normalized data did not. Conclusions If RGs are coexpressed but are not independent of the experimental conditions the stability criteria based on inter- and intragroup variation fail. The linear error model developed, LEMming, overcomes the dependency of using RGs for parallel qPCR measurements, besides resolving biases of both technical and biological nature in qPCR. However, to distinguish systematic errors per treated group from a global treatment effect an additional measurement is needed. Quantification of total cDNA content per sample helps to identify systematic errors.",
	author = "Ronny Feuer and Sebastian Vlaic and Janine Arlt and Oliver Sawodny and Uta Dahmen and Ulrich M. Zanger and Maria Thomas",
	doi = "10.1371/journal.pone.0135852",
	issn = "1932-6203",
	journal = "PLOS ONE",
	keywords = "Complementary DNA; Data processing; Gene Expression; Microfluidics; Polymerase chain reaction; Reverse Transcription; RNA extraction; RNA synthesis",
	month = sep,
	number = "9",
	pages = "e0135852",
	shorttitle = "{LEMming}",
	title = "{{LEMming}: {A} {Linear} {Error} {Model} to {Normalize} {Parallel} {Quantitative} {Real}-{Time} {PCR} ({qPCR}) {Data} as an {Alternative} to {Reference} {Gene} {Based} {Methods}}",
	url = "http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0135852",
	urldate = "2016-06-15",
	volume = "10",
	year = "2015"
}

@article{forsberg_high-throughput_2016,
	author = "Christina Forsberg and Linda Jansson and Ricky Ansell and Johannes Hedman",
	doi = "10.1016/j.fsigen.2016.06.004",
	issn = "18724973",
	journal = "Forensic Science International: Genetics",
	language = "en",
	month = sep,
	pages = "158--163",
	title = "{High-throughput {DNA} extraction of forensic adhesive tapes}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1872497316301053",
	urldate = "2017-04-11",
	volume = "24",
	year = "2016"
}

@inproceedings{fu_cluster_2008,
	author = "Huaiguo Fu",
	booktitle = "{Proceedings of the 7th {WSEAS} international conference on artificial intelligence, knowledge engineering and data bases ({AIKED}{\rq}08)}",
	pages = "576--581",
	title = "{Cluster analysis and association analysis for the same data}",
	url = "http://www.wseas.us/e-library/conferences/2008/uk/AIKED/AIKED-88.pdf",
	urldate = "2017-07-25",
	year = "2008"
}

@article{geng_minimizing_2015,
	author = "Tao Geng and Richard A. Mathies",
	doi = "10.1016/j.fsigen.2014.10.007",
	issn = "18724973",
	journal = "Forensic Science International: Genetics",
	language = "en",
	month = jan,
	pages = "203--209",
	title = "{Minimizing inhibition of {PCR}-{STR} typing using digital agarose droplet microfluidics}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1872497314002233",
	urldate = "2016-10-25",
	volume = "14",
	year = "2015"
}

@article{geng_single-cell_2014,
	abstract = "A short tandem repeat (STR) typing method is developed for forensic identification of individual cells. In our strategy, monodisperse 1.5 nL agarose-in-oil droplets are produced with a high frequency using a microfluidic droplet generator. Statistically dilute single cells, along with primer-functionalized microbeads, are randomly compartmentalized in the droplets. Massively parallel single-cell droplet polymerase chain reaction (PCR) is performed to transfer replicas of desired STR targets from the single-cell genomic DNA onto the coencapsulated microbeads. These DNA-conjugated beads are subsequently harvested and reamplified under statistically dilute conditions for conventional capillary electrophoresis (CE) STR fragment size analysis. The 9-plex STR profiles of single cells from both pure and mixed populations of GM09947 and GM09948 human lymphoid cells show that all alleles are correctly called and allelic drop-in/drop-out is not observed. The cell mixture study exhibits a good linear relationship between the observed and input cell ratios in the range of 1:1 to 10:1. Additionally, the STR profile of GM09947 cells could be deduced even in the presence of a high concentration of cell-free contaminating 9948 genomic DNA. Our method will be valuable for the STR analysis of samples containing mixtures of cells/DNA from multiple contributors and for low-concentration samples.",
	author = "Tao Geng and Richard Novak and Richard A. Mathies",
	doi = "10.1021/ac403137h",
	issn = "0003-2700",
	journal = "Analytical Chemistry",
	month = jan,
	number = "1",
	pages = "703--712",
	title = "{Single-{Cell} {Forensic} {Short} {Tandem} {Repeat} {Typing} within {Microfluidic} {Droplets}}",
	url = "http://dx.doi.org/10.1021/ac403137h",
	urldate = "2016-12-04",
	volume = "86",
	year = "2014"
}

@article{gentleman_2004,
	abstract = "The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.",
	author = "Robert C Gentleman and Vincent J Carey and Douglas M Bates and Ben Bolstad and Marcel Dettling and Sandrine Dudoit and Byron Ellis and Laurent Gautier and Yongchao Ge and Jeff Gentry and Kurt Hornik and Torsten Hothorn and Wolfgang Huber and Stefano Iacus and Rafael Irizarry and Friedrich Leisch and Cheng Li and Martin Maechler and Anthony J Rossini and Gunther Sawitzki and Colin Smith and Gordon Smyth and Luke Tierney and Jean Y H Yang and Jianhua Zhang",
	doi = "10.1186/gb-2004-5-10-r80",
	issn = "1465-6914",
	journal = "Genome Biology",
	keywords = "Computational Biology; Internet; Reproducibility of Results; Software",
	language = "eng",
	note = "{PMID:} 15461798 {PMCID:} {PMC545600}",
	number = "10",
	pages = "R80",
	shorttitle = "Bioconductor",
	title = "{Bioconductor: open software development for computational biology and bioinformatics}",
	volume = "5",
	year = "2004"
}

@article{george_development_2016,
	abstract = "Severe heart diseases such as myocarditis and cardiomyopathy are often characterized by progressive damages of contractile heart tissue which ultimately can lead to terminal heart failure. There is a need for relevant in vitro cultures of human cardiomyocytes to study pathogenic processes and to perform pharmacological testing of new heart drugs. By using the upcyte/EPCC (enhanced primary cell culture) approach for direct multiplication of organ-specific cells, we established proliferating human cardiomyocyte cultures derived from atrial appendages. For qualitative cardiac expression profiling we established a comprehensive set of multiplex PCR assays, selected from a panel of 32 genes, to rapidly screen changes at the transcriptional level in human ventricular and atrial cardiomyocytes. Our multiplex PCR approach revealed some donor variability of native atrial heart tissue that need to be confirmed by further studies with more samples. Our initial studies further indicated that characteristic heart muscle cell markers such as MLC-2 a , MLC-2v , CHRM2 , ADRB1 , DES , EDRNB , C x40 and KCNA5 were down-regulated when isolated cardiomyocytes were taken into primary cell culture. Compared to native heart tissue, proliferating atrial cardiomyocytes lacked expression of those cardiac markers but still expressed MYCD , GATA-4 , Cx43 , SERCA2 , BNP , Tbx5 , EDNRA and ACTB . Surprisingly, atrium-derived cardiomyocytes started to express NFAc4 in passage three, and cardiomyocyte marker expressions of Cx43 and BNP were even increased over cultivation time. In conclusion, our novel multiplex PCR assays should be useful for expression profiling of native heart tissues from patients with different disease conditions and for characterization of in vitro cardiomyocyte cultures.",
	author = "Sandra George and Stefan R{\"o}diger and Christian Schr{\"o}der and Michael Knaut and Jan-Heiner K{\"u}pper",
	doi = "10.3233/JCB-15025",
	issn = "2352-3689",
	journal = "Journal of Cellular Biotechnology",
	month = jan,
	number = "1",
	pages = "35--55",
	title = "{Development of multiplex {PCR} systems for expression profiling of human cardiomyocytes induced to proliferate by lentivirus transduction of upcyte genes}",
	url = "http://content.iospress.com/articles/journal-of-cellular-biotechnology/jcb15025",
	urldate = "2016-09-16",
	volume = "2",
	year = "2016"
}

@article{greene_big_2014,
	abstract = "Recent technological advances allow for high throughput profiling of biological systems in a cost-efficient manner. The low cost of data generation is leading us to the ``big data'' era. The availability of big data provides unprecedented opportunities but also raises new challenges for data mining and analysis. In this review, we introduce key concepts in the analysis of big data, including both ``machine learning'' algorithms as well as ``unsupervised'' and ``supervised'' examples of each. We note packages for the R programming language that are available to perform machine learning analyses. In addition to programming based solutions, we review webservers that allow users with limited or no programming background to perform these analyses on large data compendia. J. Cell. Physiol. 229: 1896--1900, 2014. Â© 2014 Wiley Periodicals, Inc.",
	author = "Casey S. Greene and Jie Tan and Matthew Ung and Jason H. Moore and Chao Cheng",
	copyright = "Â© 2014 Wiley Periodicals, Inc.",
	doi = "10.1002/jcp.24662",
	issn = "1097-4652",
	journal = "Journal of Cellular Physiology",
	language = "en",
	number = "12",
	pages = "1896--1900",
	title = "{Big {Data} {Bioinformatics}}",
	url = "http://onlinelibrary.wiley.com/doi/10.1002/jcp.24662/abstract",
	urldate = "2015-10-04",
	volume = "229",
	year = "2014"
}

@article{halpern_str_2011,
	abstract = "Abstract: The most common markers used in forensic genetics are short tandem repeats (STRs), the alleles of which are separated and analyzed by length using capillary electrophoresis (CE). In this work, proof of concept of a unique STR genotyping approach has been demonstrated using asymmetric PCR and a fluorescence resonance energy transfer (FRET)-based hybridization analysis that combines fluorophore-labeled allele-specific probes and a DNA intercalating dye (dpFRET) in a melt match/mismatch analysis format. The system was successfully tested against both a simple (TPOX) and a complex (D3S1358) loci, demonstrated a preliminary detection limit of {\textless}10 genomic equivalents with no allelic dropout and mixture identification in both laboratory-generated and clinical samples. With additional development, this approach has the potential to contribute to advancing the use of STR loci for forensic applications and related fields.",
	author = "Micah D. Halpern and Jack Ballantyne",
	doi = "10.1111/j.1556-4029.2010.01549.x",
	issn = "1556-4029",
	journal = "Journal of Forensic Sciences",
	keywords = "Fluorescence Resonance Energy Transfer; forensic science; DNA typing; short tandem repeat; intercalating dye; fluorophore probe; melt curve analysis",
	language = "en",
	month = jan,
	number = "1",
	pages = "36--45",
	title = "{An {STR} {Melt} {Curve} {Genotyping} {Assay} for {Forensic} {Analysis} {Employing} an {Intercalating} {Dye} {Probe} {FRET}*}",
	url = "http://onlinelibrary.wiley.com/doi/10.1111/j.1556-4029.2010.01549.x/abstract",
	urldate = "2016-12-21",
	volume = "56",
	year = "2011"
}

@article{hedman_applying_2011,
	author = "J. Hedman and C. Dufva and L. Nor{\'e}n and C. Ansell and L. Albinsson and R. Ansell",
	doi = "10.1016/j.fsigss.2011.09.037",
	issn = "18751768",
	journal = "Forensic Science International: Genetics Supplement Series",
	language = "en",
	month = dec,
	number = "1",
	pages = "e349--e350",
	title = "{Applying a {PCR} inhibitor tolerant {DNA} polymerase blend in forensic {DNA} profiling}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1875176811001752",
	urldate = "2017-05-17",
	volume = "3",
	year = "2011"
}

@article{hedman_synergy_2010,
	author = "Johannes Hedman and Anders Nordgaard and Charlotte Dufva and Birgitta Rasmusson and Ricky Ansell and Peter R{\aa}dstr{\"o}m",
	doi = "10.1016/j.ab.2010.06.028",
	issn = "00032697",
	journal = "Analytical Biochemistry",
	language = "en",
	month = oct,
	number = "2",
	pages = "192--200",
	title = "{Synergy between {DNA} polymerases increases polymerase chain reaction inhibitor tolerance in forensic {DNA} analysis}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S0003269710003817",
	urldate = "2017-05-17",
	volume = "405",
	year = "2010"
}

@article{hellemans_2007,
	abstract = "{qBase}, a free program for the management and automated analysis of {qPCR} data, is described, Although quantitative {PCR} ({qPCR}) is becoming the method of choice for expression profiling of selected genes, accurate and straightforward processing of the raw measurements remains a major hurdle. Here we outline advanced and universally applicable models for relative quantification and inter-run calibration with proper error propagation along the entire calculation track. These models and algorithms are implemented in {qBase}, a free program for the management and automated analysis of {qPCR} data.",
	author = "Jan Hellemans and Geert Mortier and Anne {De Paepe} and Frank Speleman and Jo Vandesompele",
	doi = "10.1186/gb-2007-8-2-r19",
	issn = "1465-6906",
	journal = "Genome Biology",
	number = "2",
	pages = "R19",
	pmcid = "PMC1852402",
	pmid = "17291332",
	title = "{{qBase} relative quantification framework and software for management and automated analysis of real-time quantitative {PCR} data}",
	url = "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1852402/",
	urldate = "2014-09-11",
	volume = "8",
	year = "2007"
}

@book{herrera_multiple_2016,
	address = "Cham",
	author = "Francisco Herrera and Sebasti{\'a}n Ventura and Rafael Bello and Chris Cornelis and Amelia Zafra and D{\'a}nel S{\'a}nchez-Tarrag{\'o} and Sarah Vluymans",
	isbn = "978-3-319-47758-9 978-3-319-47759-6",
	language = "en",
	note = "DOI: 10.1007/978-3-319-47759-6",
	publisher = "Springer International Publishing",
	title = "{Multiple {Instance} {Learning}}",
	url = "http://link.springer.com/10.1007/978-3-319-47759-6",
	urldate = "2017-07-31",
	year = "2016"
}

@article{hofmann_2013,
	abstract = "Graphics are good for showing the information in datasets and for complementing modelling. Sometimes graphics show information models miss, sometimes graphics help to make model results more understandable, and sometimes models show whether information from graphics has statistical support or not. It is the interplay of the two approaches that is valuable. Graphics could be used a lot more in R examples and we explore this idea with some datasets available in R packages.",
	author = "Heike Hofmann and Antony Unwin and Dianne Cook",
	journal = "The R Journal",
	month = jun,
	number = "1",
	pages = "117--130",
	title = "{Let Graphics Tell the Story - Datasets in R}",
	url = "http://journal.r-project.org/archive/2013-1/RJournal_2013-1_hofmann-unwin-cook.pdf",
	volume = "5",
	year = "2013"
}

@article{hopwood_integrated_2010,
	author = "Andrew J. Hopwood and Cedric Hurth and Jianing Yang and Zhi Cai and Nina Moran and John G. Lee-Edghill and Alan Nordquist and Ralf Lenigk and Matthew D. Estes and John P. Haley and Colin R. McAlister and Xiaojia Chen and Carla Brooks and Stan Smith and Keith Elliott and Pieris Koumi and Frederic Zenhausern and Gillian Tully",
	doi = "10.1021/ac101355r",
	issn = "0003-2700, 1520-6882",
	journal = "Analytical Chemistry",
	language = "en",
	month = aug,
	number = "16",
	pages = "6991--6999",
	shorttitle = "Integrated {Microfluidic} {System} for {Rapid} {Forensic} {DNA} {Analysis}",
	title = "{Integrated {Microfluidic} {System} for {Rapid} {Forensic} {DNA} {Analysis}: {Sample} {Collection} to {DNA} {Profile}}",
	url = "http://pubs.acs.org/doi/abs/10.1021/ac101355r",
	urldate = "2016-10-25",
	volume = "82",
	year = "2010"
}

@article{hornik_strucplot_2006,
	author = "Kurt Hornik and Achim Zeileis and David Meyer",
	journal = "Journal of Statistical Software",
	number = "3",
	pages = "1--48",
	shorttitle = "The strucplot framework",
	title = "{The strucplot framework: visualizing multi-way contingency tables with vcd}",
	url = "http://epub.wu.ac.at/id/eprint/3984",
	urldate = "2017-08-28",
	volume = "17",
	year = "2006"
}

@book{hothorn_handbook_2014,
	address = "Oakville",
	author = "Torsten Hothorn and Brian S. Everitt",
	edition = "3rd",
	isbn = "978-1-4822-0458-2",
	language = "English",
	month = jun,
	note = "OCLC: 885455227",
	publisher = "Chapman and Hall/CRC",
	title = "{A {Handbook} of {Statistical} {Analyses} using {R}, {Third} {Edition}}",
	year = "2014"
}

@article{hothorn_unbiased_2006,
	author = "Torsten Hothorn and Kurt Hornik and Achim Zeileis",
	doi = "10.1198/106186006X133933",
	issn = "1061-8600, 1537-2715",
	journal = "Journal of Computational and Graphical Statistics",
	language = "en",
	month = sep,
	number = "3",
	pages = "651--674",
	shorttitle = "Unbiased {Recursive} {Partitioning}",
	title = "{Unbiased {Recursive} {Partitioning}: {A} {Conditional} {Inference} {Framework}}",
	url = "http://www.tandfonline.com/doi/abs/10.1198/106186006X133933",
	urldate = "2017-07-25",
	volume = "15",
	year = "2006"
}

@article{huggett_2013,
	abstract = "There is growing interest in digital {PCR} ({dPCR)} because technological progress makes it a practical and increasingly affordable technology. {dPCR} allows the precise quantification of nucleic acids, facilitating the measurement of small percentage differences and quantification of rare variants. {dPCR} may also be more reproducible and less susceptible to inhibition than quantitative real-time {PCR} ({qPCR).} Consequently, {dPCR} has the potential to have a substantial impact on research as well as diagnostic applications. However, as with {qPCR}, the ability to perform robust meaningful experiments requires careful design and adequate controls. To assist independent evaluation of experimental data, comprehensive disclosure of all relevant experimental details is required. To facilitate this process we present the Minimum Information for Publication of Quantitative Digital {PCR} Experiments guidelines. This report addresses known requirements for {dPCR} that have already been identified during this early stage of its development and commercial implementation. Adoption of these guidelines by the scientific community will help to standardize experimental protocols, maximize efficient utilization of resources, and enhance the impact of this promising new technology.",
	author = "Jim F Huggett and Carole A Foy and Vladimir Benes and Kerry Emslie and Jeremy A Garson and Ross Haynes and Jan Hellemans and Mikael Kubista and Reinhold D Mueller and Tania Nolan and Michael W Pfaffl and Gregory L Shipley and Jo Vandesompele and Carl T Wittwer and Stephen A Bustin",
	doi = "10.1373/clinchem.2013.206375",
	issn = "1530-8561",
	journal = "Clinical {C}hemistry",
	keywords = "Computers; Guidelines as Topic; Real-Time Polymerase Chain Reaction",
	language = "eng",
	month = jun,
	note = "{PMID:} 23570709",
	number = "6",
	pages = "892--902",
	shorttitle = "The digital {MIQE} guidelines",
	title = "{The digital {MIQE} guidelines: Minimum Information for Publication of Quantitative Digital {PCR} Experiments}",
	volume = "59",
	year = "2013"
}

@book{igual_introduction_2017,
	address = "Cham",
	author = "Laura Igual and Santi Segu{\'i}",
	isbn = "978-3-319-50016-4 978-3-319-50017-1",
	note = "DOI: 10.1007/978-3-319-50017-1",
	publisher = "Springer International Publishing",
	series = "{Undergraduate {Topics} in {Computer} {Science}}",
	title = "{Introduction to {Data} {Science}}",
	url = "http://link.springer.com/10.1007/978-3-319-50017-1",
	urldate = "2017-07-26",
	year = "2017"
}

@inproceedings{jambukia_classification_2015,
	author = "Shweta H. Jambukia and Vipul K. Dabhi and Harshadkumar B. Prajapati",
	booktitle = "{Computer {Engineering} and {Applications} ({ICACEA}), 2015 {International} {Conference} on {Advances} in {Computer Engineering} and {Applications}}",
	pages = "714--721",
	publisher = "IEEE",
	shorttitle = "Classification of {ECG} signals using machine learning techniques",
	title = "{Classification of {ECG} signals using machine learning techniques: {A} survey}",
	url = "http://ieeexplore.ieee.org/abstract/document/7164783/",
	urldate = "2017-06-25",
	year = "2015"
}

@article{james_ecp:_2013,
	author = "Nicholas A. James and David S. Matteson",
	journal = "arXiv preprint arXiv:1309.3295",
	shorttitle = "ecp",
	title = "{{ecp}: {An} {R} package for nonparametric multiple change point analysis of multivariate data}",
	url = "https://arxiv.org/abs/1309.3295",
	urldate = "2017-06-25",
	year = "2013"
}

@book{james_introduction_2013,
	address = "New York, NY",
	author = "Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani",
	isbn = "978-1-4614-7137-0 978-1-4614-7138-7",
	note = "DOI: 10.1007/978-1-4614-7138-7",
	publisher = "Springer New York",
	series = "{Springer {Texts} in {Statistics}}",
	title = "{An {Introduction} to {Statistical} {Learning}}",
	url = "http://link.springer.com/10.1007/978-1-4614-7138-7",
	urldate = "2017-10-12",
	volume = "103",
	year = "2013"
}

@article{jeffreys_individual-specific_1985,
	abstract = "Individual-specific {\lq}fingerprints{\rq} of human DNA",
	author = "A. J. Jeffreys and V. Wilson and S. L. Thein",
	copyright = "1985 Nature Publishing Group",
	doi = "10.1038/316076a0",
	issn = "1476-4687",
	journal = "Nature",
	language = "En",
	month = jul,
	number = "6023",
	pages = "76",
	title = "{Individual-specific {\lq}fingerprints{\rq} of human {DNA}}",
	url = "https://www.nature.com/articles/316076a0",
	urldate = "2017-12-21",
	volume = "316",
	year = "1985"
}

@article{jobling_y_1997,
	abstract = "The male specificity of the human Y chromosome makes it potentially useful in forensic studies and paternity testing, and markers are now available which will allow its usefulness to be assessed in practice. However, while it can be used confidently for exclusions, the unusual properties of the Y mean that inclusions will be very difficult to make: haplotypes are confined within lineages, so population sub-structuring is a major problem, and many male relatives of a suspect will share his Y chromosome. Y haplotyping is most likely to find application in special instances, such as deficiency cases in paternity testing and in the analysis of mixtures of male and female DNA, or in combination with autosomal markers.",
	author = "M. A. Jobling and A. Pandya and C. Tyler-Smith",
	issn = "0937-9827",
	journal = "International Journal of Legal Medicine",
	keywords = "Humans; Female; Male; Genetics; Population; Genetic Markers; Haplotypes; Gene Frequency; Paternity; Polymorphism; Genetic; Y Chromosome",
	language = "eng",
	number = "3",
	pages = "118--124",
	pmid = "9228562",
	title = "{The {Y} chromosome in forensic analysis and paternity testing}",
	volume = "110",
	year = "1997"
}

@manual{kmlShape,
	author = "Christophe Genolini",
	note = "R package version 0.9.5",
	title = "{kmlShape: K-Means for Longitudinal Data using Shape-Respecting Distance}",
	url = "https://CRAN.R-project.org/package=kmlShape",
	year = "2016"
}

@article{kowarik_sparktable:_2014,
	author = "Alexander Kowarik and Bernhard Meindl and Matthias Templ",
	journal = "The R Journal",
	number = "1",
	pages = "24--37",
	shorttitle = "{sparkTable}",
	title = "{{sparkTable}: {Generating} graphical tables for websites and documents with {R}}",
	url = "https://publik.tuwien.ac.at/files/PubDat_228663.pdf",
	urldate = "2017-06-25",
	volume = "7",
	year = "2014"
}

@article{kruschke_bayesian_2013,
	author = "John K. Kruschke",
	journal = "Journal of Experimental Psychology: General",
	number = "2",
	pages = "573",
	title = "{Bayesian estimation supersedes the t test.}",
	url = "http://psycnet.apa.org/journals/xge/142/2/573/",
	urldate = "2017-06-26",
	volume = "142",
	year = "2013"
}

@article{kyoda_biological_2015,
	abstract = "Motivation: Recent progress in live-cell imaging and modeling techniques has resulted in generation of a large amount of quantitative data (from experimental measurements and computer simulations) on spatiotemporal dynamics of biological objects such as molecules, cells and organisms. Although many research groups have independently dedicated their efforts to developing software tools for visualizing and analyzing these data, these tools are often not compatible with each other because of different data formats. Results: We developed an open unified format, Biological Dynamics Markup Language (BDML; current version: 0.2), which provides a basic framework for representing quantitative biological dynamics data for objects ranging from molecules to cells to organisms. BDML is based on Extensible Markup Language (XML). Its advantages are machine and human readability and extensibility. BDML will improve the efficiency of development and evaluation of software tools for data visualization and analysis. Availability and implementation: A specification and a schema file for BDML are freely available online at http://ssbd.qbic.riken.jp/bdml/. Contact: sonami@riken.jp Supplementary Information: Supplementary data are available at Bioinformatics online.",
	author = "Koji Kyoda and Yukako Tohsato and Kenneth H. L. Ho and Shuichi Onami",
	doi = "10.1093/bioinformatics/btu767",
	issn = "1367-4803, 1460-2059",
	journal = "Bioinformatics",
	number = "7",
	pages = "1044--1052",
	pmid = "25414366",
	shorttitle = "Biological {Dynamics} {Markup} {Language} ({BDML})",
	title = "{Biological {Dynamics} {Markup} {Language} ({BDML}): an open format for representing quantitative biological dynamics data}",
	url = "http://bioinformatics.oxfordjournals.org/content/31/7/1044",
	volume = "31",
	year = "2015"
}

@book{lee_statistical_2010,
	author = "J. K. Lee",
	isbn = "978-0-470-56763-0",
	publisher = "Wiley",
	title = "{Statistical {Bioinformatics}: {For} {Biomedical} and {Life} {Science} {Researchers}}",
	url = "https://books.google.de/books?id=aT1MBGtxSNsC",
	year = "2010"
}

@article{liu_direct_2014,
	author = "Jason Yingjie Liu",
	doi = "10.1016/j.fsigen.2014.03.003",
	issn = "18724973",
	journal = "Forensic Science International: Genetics",
	language = "en",
	month = jul,
	pages = "96--104",
	title = "{Direct {qPCR} quantification of unprocessed forensic casework samples}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1872497314000441",
	urldate = "2017-06-23",
	volume = "11",
	year = "2014"
}

@article{liu_r_2014,
	abstract = "It is scientifically and ethically imperative that the results of statistical analysis of biomedical research data be computationally reproducible in the sense that the reported results can be easily recapitulated from the study data. Some statistical analyses are computationally a function of many data files, program files, and other details that are updated or corrected over time. In many applications, it is infeasible to manually maintain an accurate and complete record of all these details about a particular analysis. PMID: 24886202",
	author = "Zhifa Liu and Stan Pounds",
	copyright = "2014 Liu and Pounds; licensee BioMed Central Ltd.",
	doi = "10.1186/1471-2105-15-138",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	language = "en",
	month = may,
	number = "1",
	pages = "138",
	pmid = "24886202",
	title = "{An {R} package that automatically collects and archives details for reproducible computing}",
	url = "http://www.biomedcentral.com/1471-2105/15/138/abstract",
	urldate = "2014-07-01",
	volume = "15",
	year = "2014"
}

@incollection{lundberg_unified_2017,
	author = "Scott M Lundberg and Su-In Lee",
	booktitle = "{Advances in {Neural} {Information} {Processing} {Systems} 30}",
	editor = "I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett",
	pages = "4768--4777",
	publisher = "Curran Associates, Inc.",
	title = "{A {Unified} {Approach} to {Interpreting} {Model} {Predictions}}",
	url = "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf",
	urldate = "2017-12-25",
	year = "2017"
}

@article{m_romeika_recent_2014,
	author = "jennifer m romeika",
	doi = "10.4172/2157-7145.s12-001",
	issn = "21577145",
	journal = "journal of forensic research",
	number = "01",
	title = "{recent {advances} in {forensic} {dna} {analysis}}",
	url = "http://www.omicsonline.org/open-access/recent-advances-in-forensic-dna-analysis-2157-7145.s12-001.php?aid=20400",
	urldate = "2016-12-04",
	volume = "s12",
	year = "2014"
}

@article{mallona_chainy:_nodate,
	author = "Izaskun Mallona and Anna D{\'i}ez-Villanueva and Berta Mart{\'i}n and Miguel A. Peinado",
	doi = "10.1093/bioinformatics/btw839",
	journal = "Bioinformatics",
	shorttitle = "Chainy",
	title = "{Chainy: an universal tool for standardized relative quantification in real-time {PCR}}",
	url = "https://academic.oup.com/bioinformatics/article-abstract/doi/10.1093/bioinformatics/btw839/2840141/Chainy-an-universal-tool-for-standardized-relative",
	urldate = "2017-04-23",
	year = "2017"
}

@article{mao_characterization_2007,
	abstract = {Background EvaGreen (EG) is a newly developed DNA-binding dye that has recently been used in quantitative real-time PCR (qPCR), post-PCR DNA melt curve analysis and several other applications. However, very little is known about the physicochemical properties of the dye and their relevance to the applications, particularly to qPCR and post PCR DNA melt curve analysis. In this paper, we characterized EG along with a widely used qPCR dye, SYBR Green I (SG), for their DNA-binding properties and stability, and compared their performance in qPCR under a variety of conditions. Results This study systematically compared the DNA binding profiles of the two dyes under different conditions and had these findings: a) EG had a lower binding affinity for both double-stranded DNA (dsDNA) and single-stranded DNA (ssDNA) than SG; b) EG showed no apparent preference for either GC- or AT-rich sequence while SG had a slight preference for AT-rich sequence; c) both dyes showed substantially lower affinity toward ssDNA than toward dsDNA and even lower affinity toward shorter ssDNA fragments except that this trend was more pronounced for EG. Our results also demonstrated that EG was stable both under PCR condition and during routine storage and handling. In the comparative qPCR study, both EG and SG exhibited PCR interference when used at high dye concentration, as evident from delayed Ct and/or nonspecific product formation. The problem worsened when the chain extension time was shortened or when the amplicon size was relatively long ({\textgreater}500 bp). However, qPCR using EG tolerated a significantly higher dye concentration, thus permitting a more robust PCR signal as well as a sharper and stronger DNA melt peak. These differences in qPCR performance between the two dyes are believed to be attributable to their differences in DNA binding profiles. Conclusion These findings suggest that an ideal qPCR dye should possess several DNA-binding characteristics, including a "just right" affinity for dsDNA and low or no affinity for ssDNA and short DNA fragments. The favorable DNA-binding profile of EG, coupled with its good stability and instrument-compatibility, should make EG a promising dye for qPCR and related applications.},
	author = "Fei Mao and Wai-Yee Leung and Xing Xin",
	doi = "10.1186/1472-6750-7-76",
	issn = "1472-6750",
	journal = "BMC Biotechnology",
	month = nov,
	pages = "76",
	pmcid = "PMC2213645",
	pmid = "17996102",
	title = "{Characterization of {EvaGreen} and the implication of its physicochemical properties for {qPCR} applications}",
	url = "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2213645/",
	urldate = "2014-03-23",
	volume = "7",
	year = "2007"
}

@article{matz_no_2013,
	abstract = "BackgroundModel-based analysis of data from quantitative reverse-transcription PCR (qRT-PCR) is potentially more powerful and versatile than traditional methods. Yet existing model-based approaches cannot properly deal with the higher sampling variances associated with low-abundant targets, nor do they provide a natural way to incorporate assumptions about the stability of control genes directly into the model-fitting process.ResultsIn our method, raw qPCR data are represented as molecule counts, and described using generalized linear mixed models under Poisson-lognormal error. A Markov Chain Monte Carlo (MCMC) algorithm is used to sample from the joint posterior distribution over all model parameters, thereby estimating the effects of all experimental factors on the expression of every gene. The Poisson-based model allows for the correct specification of the mean-variance relationship of the PCR amplification process, and can also glean information from instances of no amplification (zero counts). Our method is very flexible with respect to control genes: any prior knowledge about the expected degree of their stability can be directly incorporated into the model. Yet the method provides sensible answers without such assumptions, or even in the complete absence of control genes. We also present a natural Bayesian analogue of the ``classic'' analysis, which uses standard data pre-processing steps (logarithmic transformation and multi-gene normalization) but estimates all gene expression changes jointly within a single model. The new methods are considerably more flexible and powerful than the standard delta-delta Ct analysis based on pairwise t-tests.ConclusionsOur methodology expands the applicability of the relative-quantification analysis protocol all the way to the lowest-abundance targets, and provides a novel opportunity to analyze qRT-PCR data without making any assumptions concerning target stability. These procedures have been implemented as the MCMC.qpcr package in R.",
	author = "Mikhail V. Matz and Rachel M. Wright and James G. Scott",
	doi = "10.1371/journal.pone.0071448",
	journal = "PLoS ONE",
	month = aug,
	number = "8",
	pages = "e71448",
	shorttitle = "No {Control} {Genes} {Required}",
	title = "{No {Control} {Genes} {Required}: {Bayesian} {Analysis} of {qRT}-{PCR} {Data}}",
	url = "http://dx.doi.org/10.1371/journal.pone.0071448",
	urldate = "2015-05-04",
	volume = "8",
	year = "2013"
}

@article{mcnevin_assessment_2013,
	author = "D. McNevin and C. Santos and A. G{\'o}mez-Tato and J. {\'A}lvarez-Dios and M. Casares de Cal and R. Daniel and C. Phillips and M.V. Lareu",
	doi = "10.1016/j.fsigss.2013.10.032",
	issn = "18751768",
	journal = "Forensic Science International: Genetics Supplement Series",
	language = "en",
	number = "1",
	pages = "e63--e64",
	title = "{An assessment of {Bayesian} and multinomial logistic regression classification systems to analyse admixed individuals}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1875176813000334",
	urldate = "2017-02-10",
	volume = "4",
	year = "2013"
}

@article{millard_adaptive_2011,
	abstract = "Whereas genomic data are universally machine-readable, data from imaging, multiplex biochemistry, flow cytometry and other cell- and tissue-based assays usually reside in loosely organized files of poorly documented provenance. This arises because the relational databases used in genomic research are difficult to adapt to rapidly evolving experimental designs, data formats and analytic algorithms. Here we describe an adaptive approach to managing experimental data based on semantically typed data hypercubes (SDCubes) that combine hierarchical data format 5 (HDF5) and extensible markup language (XML) file types. We demonstrate the application of SDCube-based storage using ImageRail, a software package for high-throughput microscopy. Experimental design and its day-to-day evolution, not rigid standards, determine how ImageRail data are organized in SDCubes. We applied ImageRail to collect and analyze drug dose-response landscapes in human cell lines at single-cell resolution.",
	author = "Bjorn L. Millard and Mario Niepel and Michael P. Menden and Jeremy L. Muhlich and Peter K. Sorger",
	copyright = "Â© 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.",
	doi = "10.1038/nmeth.1600",
	issn = "1548-7091",
	journal = "Nature Methods",
	number = "6",
	pages = "487--492",
	title = "{Adaptive informatics for multifactorial and high-content biological data}",
	url = "http://www.nature.com/nmeth/journal/v8/n6/full/nmeth.1600.html",
	volume = "8",
	year = "2011"
}

@article{pan_real-time_1985,
	abstract = "We have developed a real-time algorithm for detection of the QRS complexes of ECG signals. It reliably recognizes QRS complexes based upon digital analyses of slope, amplitude, and width. A special digital bandpass filter reduces false detections caused by the various types of interference present in ECG signals. This filtering permits use of low thresholds, thereby increasing detection sensitivity. The algorithm automatically adjusts thresholds and parameters periodically to adapt to such ECG changes as QRS morphology and heart rate. For the standard 24 h MIT/BIH arrhythmia database, this algorithm correctly detects 99.3 percent of the QRS complexes.",
	author = "J. Pan and W. J. Tompkins",
	doi = "10.1109/TBME.1985.325532",
	issn = "0018-9294",
	journal = "IEEE Transactions on Biomedical Engineering",
	keywords = "Analog-Digital Conversion; Band pass filters; Computer displays; Databases; Detection algorithms; Detectors; Digital filters; Electrocardiography; Evaluation Studies as Topic; Filtering; Filtration; Humans; Interference; Mathematics; Noise reduction",
	month = mar,
	number = "3",
	pages = "230--236",
	title = "{A {Real}-{Time} {QRS} {Detection} {Algorithm}}",
	volume = "BME-32",
	year = "1985"
}

@article{perkins_readqpcr_2012,
	abstract = "Measuring gene transcription using real-time reverse transcription polymerase chain reaction (RT-qPCR) technology is a mainstay of molecular biology. Technologies now exist to measure the abundance of many transcripts in parallel. The selection of the optimal reference gene for the normalisation of this data is a recurring problem, and several algorithms have been developed in order to solve it. So far nothing in R exists to unite these methods, together with other functions to read in and normalise the data using the chosen reference gene(s). PMID: 22748112",
	author = "James R. Perkins and John M. Dawes and Steve B. McMahon and David LH Bennett and Christine Orengo and Matthias Kohl",
	copyright = "2012 Perkins et al.; licensee BioMed Central Ltd.",
	doi = "10.1186/1471-2164-13-296",
	issn = "1471-2164",
	journal = "BMC Genomics",
	language = "en",
	month = jul,
	number = "1",
	pages = "296",
	pmid = "22748112",
	shorttitle = "{ReadqPCR} and {NormqPCR}",
	title = "{{ReadqPCR} and {NormqPCR}: {R} packages for the reading, quality checking and normalisation of {RT}-{qPCR} quantification cycle ({Cq}) data}",
	url = "http://www.biomedcentral.com/1471-2164/13/296/abstract",
	urldate = "2014-04-27",
	volume = "13",
	year = "2012"
}

@article{pilhoefer_new_2013,
	author = "Alexander Pilhoefer and Antony Unwin and {others}",
	journal = "Journal of Statistical Software",
	number = "7",
	pages = "1--25",
	shorttitle = "New approaches in visualization of categorical data",
	title = "{New approaches in visualization of categorical data: {R} package extracat}",
	url = "https://www.jstatsoft.org/article/view/v053i07/v53i07.pdf",
	urldate = "2017-08-28",
	volume = "53",
	year = "2013"
}

@article{reed_high-resolution_2007,
	abstract = "High-resolution melting of {DNA} is a simple solution for genotyping, mutation scanning and sequence matching. The melting profile of a {PCR} product depends on its {GC} content, length, sequence and heterozygosity and is best monitored with saturating dyes that fluoresce in the presence of double-stranded {DNA}. Genotyping of most variants is possible by the melting temperature of the {PCR} products, while all variants can be genotyped with unlabeled probes. Mutation scanning and sequence matching depend on sequence differences that result in heteroduplexes that change the shape of the melting curve. High-resolution {DNA} melting has several advantages over other genotyping and scanning methods, including an inexpensive closed tube format that is homogenous, accurate and rapid. Owing to its simplicity and speed, the method is a good fit for personalized medicine as a rapid, inexpensive method to predict therapeutic response.",
	author = "Gudrun H. Reed and Jana O. Kent and Carl T. Wittwer",
	date = "2007-06",
	doi = "10.2217/14622416.8.6.597",
	issn = "1744-8042",
	journaltitle = "Pharmacogenomics",
	keywords = "Animals; {DNA} Mutational Analysis; Hot Temperature; Humans; Molecular Diagnostic Techniques; Nucleic Acid Denaturation",
	number = "6",
	pages = "597--608",
	pmid = "17559349",
	shortjournal = "Pharmacogenomics",
	title = "{High-resolution {DNA} melting analysis for simple and efficient molecular diagnostics}",
	volume = "8"
}

@article{reja_screenclust:_2010,
	author = "Valin Reja and Alister Kwok and Glenn Stone and Linsong Yang and Andreas Missel and Christoph Menzel and Brant Bassam",
	doi = "10.1016/j.ymeth.2010.02.006",
	issn = "10462023",
	journal = "Methods",
	language = "en",
	month = apr,
	number = "4",
	pages = "S10--S14",
	shorttitle = "{ScreenClust}",
	title = "{{ScreenClust}: {Advanced} statistical software for supervised and unsupervised high resolution melting ({HRM}) analysis}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1046202310000563",
	urldate = "2017-06-29",
	volume = "50",
	year = "2010"
}

@manual{ripley_rodbc_2015,
	abstract = "An ODBC database interface.",
	author = "Brian Ripley and Michael Lapsley (1999 to Oct 2002)",
	copyright = "GPL-2 {\textbar} GPL-3",
	shorttitle = "{RODBC}",
	title = "{{RODBC}: {ODBC} {Database} {Access}}",
	url = "https://cran.r-project.org/web/packages/RODBC/index.html",
	urldate = "2015-08-13",
	year = "2015"
}

@incollection{rodiger_alternative_2011,
	abstract = "Im Zeitalter der sequenzierten Genome ist der spezifische Nachweis von DNA und RNA Sequenzen eine zentrale Aufgabe molekularer Diagnostik. Die qualitative und quantitative Analyse von Nukleins{\"a}uresequenzen findet unter anderem Anwendung in der Krankheitserregerdetektion, der medizinischen Diagnostik, dem Wirkstoff-Screening in der Pharmazie und im Bereich der Systembiologie. F{\"u}r den Nachweis von Nukleins{\"a}ureanalyten existieren grundlegend zwei Ans{\"a}tze. Zum einen ist es m{\"o}glich Methoden zu verwenden, die nicht auf einer Analytvervielf{\"a}ltigung beruhen, sondern den Analyt direkt detektieren. Allerdings erfordern solche Verfahren eine Signalverst{\"a}rkung. Hier ist die Hybridisierung markierter Nachweissonden an die Zielsequenz zu nennen. Zum anderen k{\"o}nnen spezifisch Analyten in einem Reaktionsraum amplifiziert und nachgewiesen werden. Die Amplifikation erfolgt in der Regel enzymatisch, sodass eine indirekte Quantifizierung des Analyten m{\"o}glich ist. Als Erweiterung solcher Einzelparametermessungen sind Multiparameteranalysen zu betrachten, die simultan mehrere unabh{\"a}ngige Analyten in einem Reaktionsraum sowohl qualitativ als auch quantitativ erfassen. Gegen{\"u}ber Einzelmessungen bieten Multiparameteranalysen eine h{\"o}here Wirtschaftlichkeit, eine Steigerung der Bearbeitungsgeschwindigkeit, eine Reduktion des notwendigen Probenvolumens und eine Steigerung der Vergleichbarkeit der ermittelten Parameter untereinander. Der modernen Multiparameteranalytik stehen diverse Amplifikationsmethoden zur Verf{\"u}gung. Eine zentrale Rolle nimmt die PCR mit ihren zahlreichen Variationen ein. Daneben haben sich weitere Technologien etabliert, die sich grunds{\"a}tzlich von der konventionellen PCR bez{\"u}glich Reaktionsprinzip und Reaktionsbedingungen unterscheiden. Eine vergleichende Betrachtung der aktuellen Methoden ist Gegenstand dieser Abhandlung.",
	author = "Stefan R{\"o}diger and Sandra George and Carsten Schmidt and Ulrike Fr{\"o}mmel and Mirko Ruhland and Ingolf Schimke and Peter Schierack and Christian Schr{\"o}der",
	booktitle = "{Multiparameteranalytik in {Forschung} und {Praxis}}",
	isbn = "978-3-89967-703-4",
	language = "de",
	pages = "133--146",
	publisher = "Pabst Science Publishers",
	title = "{Alternative {Nukleins{\"a}ureamplifikationsverfahren} f{\"u}r die {Multiparameteranalytik}}",
	url = "DOI: 10.13140/RG.2.1.2766.1681",
	year = "2011"
}

@article{roediger_highly_2013,
	abstract = "The analysis of different biomolecules is of prime importance for life science research and medical diagnostics. Due to the discovery of new molecules and new emerging bioanalytical problems, there is an ongoing demand for a technology platform that provides a broad range of assays with a user-friendly flexibility and rapid adaptability to new applications. Here we describe a highly versatile microscopy platform, VideoScan, for the rapid and simultaneous analysis of various assay formats based on fluorescence microscopic detection. The technological design is equally suitable for assays in solution, microbead-based assays and cell pattern recognition. The multiplex real-time capability for tracking of changes under dynamic heating conditions makes it a useful tool for PCR applications and nucleic acid hybridization, enabling kinetic data acquisition impossible to obtain by other technologies using endpoint detection. The paper discusses the technological principle of the platform regarding data acquisition and processing. Microbead-based and solution applications for the detection of diverse biomolecules, including antigens, antibodies, peptides, oligonucleotides and amplicons in small reaction volumes, are presented together with a high-content detection of autoimmune antibodies using a HEp-2 cell assay. Its adaptiveness and versatility gives VideoScan a competitive edge over other bioanalytical technologies.",
	author = "Stefan R{\"o}diger and Peter Schierack and Alexander B{\"o}hm and J{\"o}rg Nitschke and Ingo Berger and Ulrike Fr{\"o}mmel and Carsten Schmidt and Mirko Ruhland and Ingolf Schimke and Dirk Roggenbuck and Werner Lehmann and Christian Schr{\"o}der",
	doi = "10.1007/10_2011_132",
	issn = "0724-6145",
	journal = "Advances in Biochemical Engineering/Biotechnology",
	keywords = "Antibodies; Biological Assay; Computer Systems; Microscopy; Fluorescence; Microspheres; Nucleic Acid Hybridization; Pathology; Molecular; Polymerase chain reaction",
	language = "eng",
	pages = "35--74",
	pmid = "22437246",
	title = "{A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies}",
	volume = "133",
	year = "2013"
}

@article{rodiger_nucleic_2014,
	abstract = "Microbead-based technologies represent elegant and versatile approaches for highly parallelized quantitative multiparameter assays. They also form the basis of various techniques for detection and quantification of nucleic acids and proteins. Nucleic acid-based methods include hybridization assays, solid-phase PCR, sequencing, and trapping assays. Microbead assays have been improved in the past decades and are now important tools in routine and point-of-care diagnostics as well as in life science. Its advances include low costs, low workload, high speed and high-throughput automation. The potential of microbead-based assays therefore is apparent, and commercial applications can be found in the detection and discrimination of single nucleotide polymorphism, of pathogens, and in trapping assays. This review provides an overview on microbead-based platforms for biosensing with a main focus on nucleic acid detection (including amplification strategies and on selected probe systems using fluorescent labeling). Specific sections cover chemical properties of microbeads, the coupling of targets onto solid surfaces, microbead probe systems (mainly oligonucleotide probes), microbead detection schemes (with subsections on suspension arrays, microfluidic devices, and immobilized microbeads), quantification of nucleic acids, PCR in solution and the detection of amplicons, and methods for solid-phase amplification. We discuss selected trends such as microbead-coupled amplification, heterogeneous and homogenous DNA hybridization assays, real-time assays, melting curve analysis, and digital microbead assays. We finally discuss the relevance and trends of the methods in terms of high-level multiplexed analysis and their potential in diagnosis and personalized medicine. Contains 211 references. Figure á…Ÿ",
	author = "Stefan R{\"o}diger and Claudia Liebsch and Carsten Schmidt and Werner Lehmann and Ute Resch-Genger and Uwe Schedler and Peter Schierack",
	doi = "10.1007/s00604-014-1243-4",
	issn = "0026-3672, 1436-5073",
	journal = "Microchimica Acta",
	keywords = "Nanochemistry; Nanotechnology; Characterization and Evaluation of Materials; Analytical Chemistry; Microengineering; Microbead; Microbead array; PCR; Microfluidic; Real-time; Multiplex",
	language = "en",
	month = aug,
	number = "11-12",
	pages = "1151--1168",
	shorttitle = "Nucleic acid detection based on the use of microbeads",
	title = "{Nucleic acid detection based on the use of microbeads: a review}",
	url = "http://link.springer.com/article/10.1007/s00604-014-1243-4",
	urldate = "2014-09-23",
	volume = "181",
	year = "2014"
}

@article{roediger2015chippcr,
	abstract = "Motivation: Both the quantitative real-time polymerase chain reaction (qPCR) and quantitative isothermal amplification (qIA) are standard methods for nucleic acid quantification. Numerous real-time read-out technologies have been developed. Despite the continuous interest in amplification-based techniques, there are only few tools for pre-processing of amplification data. However, a transparent tool for precise control of raw data is indispensable in several scenarios, for example, during the development of new instruments.Results: chipPCR is an R package for the pre-processing and quality analysis of raw data of amplification curves. The package takes advantage of R{\rq}s S4 object model and offers an extensible environment. chipPCR contains tools for raw data exploration: normalization, baselining, imputation of missing values, a powerful wrapper for amplification curve smoothing and a function to detect the start and end of an amplification curve. The capabilities of the software are enhanced by the implementation of algorithms unavailable in R, such as a 5-point stencil for derivative interpolation. Simulation tools, statistical tests, plots for data quality management, amplification efficiency/quantification cycle calculation, and datasets from qPCR and qIA experiments are part of the package. Core functionalities are integrated in GUIs (web-based and standalone shiny applications), thus streamlining analysis and report generation.Availability and implementation: http://cran.r-project.org/web/packages/chipPCR. Source code: https://github.com/michbur/chipPCR.Contact: stefan.roediger@b-tu.deSupplementary information: Supplementary data are available at Bioinformatics online.",
	author = "Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Peter Schierack",
	doi = "10.1093/bioinformatics/btv205",
	eprint = "http://bioinformatics.oxfordjournals.org/content/31/17/2900.full.pdf+html",
	journal = "Bioinformatics",
	number = "17",
	pages = "2900--2902",
	title = "{chipPCR: an R package to pre-process raw data of amplification curves}",
	url = "http://bioinformatics.oxfordjournals.org/content/31/17/2900.abstract",
	volume = "31",
	year = "2015"
}

@article{roediger_RJ_2013,
	author = "Stefan R{\"o}diger and Alexander B{\"o}hm and Ingolf Schimke",
	journal = "The R Journal",
	number = "2",
	pages = "37--53",
	title = "{Surface Melting Curve Analysis with {R}}",
	url = "http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf",
	volume = "5",
	year = "2013"
}

@article{rover_profille_2015,
	author = "T. Rover and R. Borges and D.A. Silva and E.F. Carvalho",
	doi = "10.1016/j.fsigss.2015.09.162",
	issn = "18751768",
	journal = "Forensic Science International: Genetics Supplement Series",
	language = "en",
	month = dec,
	pages = "e409--e411",
	title = "{Profille mapping {DNA} laboratories overlooking the forensic field and use of quality systems}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1875176815302195",
	urldate = "2016-12-22",
	volume = "5",
	year = "2015"
}

@manual{rpart_2017,
	author = "Terry Therneau and Beth Atkinson and Brian Ripley",
	note = "R package version 4.1-11",
	title = "{{rpart}: Recursive Partitioning and Regression Trees}",
	url = "https://CRAN.R-project.org/package=rpart",
	year = "2017"
}

@article{ruijter_2014,
	abstract = "The analysis of quantitative {PCR} data usually does not take into account the fact that the increase in fluorescence depends on the monitoring chemistry, the input of ds-{DNA} or ss-{cDNA}, and the directionality of the targeting of probes or primers. The monitoring chemistries currently available can be categorized into six groups: (A) {DNA-binding} dyes; (B) hybridization probes; (C) hydrolysis probes; (D) {LUX} primers; (E) hairpin primers; and (F) the {QZyme} system. We have determined the kinetics of the increase in fluorescence for each of these groups with respect to the input of both ds-{DNA} and ss-{cDNA.} For the latter, we also evaluated {mRNA} and {cDNA} targeting probes or primers. This analysis revealed three situations. Hydrolysis probes and {LUX} primers, compared to {DNA-binding} dyes, do not require a correction of the observed quantification cycle. Hybridization probes and hairpin primers require a correction of âˆ’1 cycle (dubbed C-lag), while the {QZyme} system requires the C-lag correction and an efficiency-dependent C-shift correction. A {PCR} efficiency value can be derived from the relative increase in fluorescence in the exponential phase of the amplification curve for all monitoring chemistries. In case of hydrolysis probes, {LUX} primers and hairpin primers, however, this should be performed after cycle 12, and for the {QZyme} system after cycle 19, to keep the overestimation of the {PCR} efficiency below 0.5 \%. Figure The {qPCR} monitoring chemistries form six groups with distinct fluorescence kinetics. The displacement of the amplification curve depends on the chemistry, {DNA} input and probe-targeting. The observed shift in Cq values can be corrected and {PCR} efficiencies can be derived.",
	author = "Jan M. Ruijter and Peter Lorenz and Jari M. Tuomi and Michael Hecker and Maurice J. B. van den Hoff",
	doi = "10.1007/s00604-013-1155-8",
	issn = "0026-3672, 1436-5073",
	journal = "Microchimica Acta",
	keywords = "Analytical Chemistry; Characterization and Evaluation of Materials; {DNA-binding} dyes; Hybridization probes; Hydrolysis probes; Microengineering; Monitoring chemistry; Nanochemistry; Nanotechnology; {PCR} efficiency; Quantitative {PCR}",
	language = "en",
	pages = "1--8",
	title = "{Fluorescent-increase kinetics of different fluorescent reporters used for {qPCR} depend on monitoring chemistry, targeted sequence, type of {DNA} input and {PCR} efficiency}",
	url = "http://link.springer.com/article/10.1007/s00604-013-1155-8",
	urldate = "2014-04-08",
	year = "2014"
}

@article{saeys_review_2007,
	author = "Y. Saeys and I. Inza and P. Larranaga",
	doi = "10.1093/bioinformatics/btm344",
	issn = "1367-4803, 1460-2059",
	journal = "Bioinformatics",
	language = "en",
	month = oct,
	number = "19",
	pages = "2507--2517",
	title = "{A review of feature selection techniques in bioinformatics}",
	url = "https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btm344",
	urldate = "2017-08-22",
	volume = "23",
	year = "2007"
}

@phdthesis{senkel_entwicklung_2017,
	address = "Senftenberg",
	author = "Roy-Arne Senkel",
	language = "German",
	month = jun,
	school = "Brandenburg University of Technology Cottbus - Senftenberg, Supervisor: Stefan R{\"o}diger",
	title = "{Entwicklung eines multiparametrischen {Systems} zur {Detektion} und {Quantifizierung} von {Humanen} {Papillomviren} mittels digitaler {PCR} und einer {Mikropartikel}-basierten {Echtzeit}-{PCR}}",
	type = "Bachelor",
	year = "2017"
}

@article{sheikh_2015,
	abstract = "Myosin light chain-2 (MYL2, also called MLC-2) is an {\textasciitilde} 19 kDa sarcomeric protein that belongs to the EF-hand calcium binding protein superfamily and exists as three major isoforms encoded by three distinct genes in mammalian striated muscle. Each of the three different MLC-2 genes (MLC-2f; fast twitch skeletal isoform, MLC-2v; cardiac ventricular and slow twitch skeletal isoform, MLC-2a; cardiac atrial isoform) has a distinct developmental expression pattern in mammals. Genetic loss-of-function studies in mice demonstrated an essential role for cardiac isoforms of MLC-2, MLC-2v and MLC-2a, in cardiac contractile function during early embryogenesis. In the adult heart, MLC-2v function is regulated by phosphorylation, which displays a specific 1`expression pattern (high in epicardium and low in endocardium) across the heart. These data along with new data from computational models, genetic mouse models, and human studies have revealed a direct role for MLC-2v phosphorylation in cross-bridge cycling kinetics, calcium-dependent cardiac muscle contraction, cardiac torsion, cardiac function and various cardiac diseases. This review focuses on the regulatory functions of MLC-2 in the embryonic and adult heart, with an emphasis on phosphorylation-driven actions of MLC-2v in adult cardiac muscle, which provide new insights into mechanisms regulating myosin cycling kinetics and human cardiac diseases.",
	author = "Farah Sheikh and Robert C. Lyon and Ju Chen",
	doi = "10.1016/j.gene.2015.06.027",
	issn = "0378-1119",
	journal = "Gene",
	keywords = "Cardiac disease; Cardiac function; Cardiac muscle; Cardiac torsion; Contraction; Heart; Myosin light chain-2 (MYL2/MLC-2); Myosin light chain kinase; Phosphorylation; Sarcomere; Ventricular myosin light chain-2",
	number = "1",
	pages = "14--20",
	title = "{Functions of myosin light chain-2 ({MYL}2) in cardiac muscle and disease}",
	url = "http://www.sciencedirect.com/science/article/pii/S0378111915007350",
	urldate = "2015-08-13",
	volume = "569",
	year = "2015"
}

@article{shin_deep_2016,
	abstract = "Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and the revival of deep CNN. CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85\% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.",
	author = "Hoo-Chang Shin and Holger R. Roth and Mingchen Gao and Le Lu and Ziyue Xu and Isabella Nogues and Jianhua Yao and Daniel Mollura and Ronald M. Summers",
	journal = "arXiv:1602.03409 [cs]",
	keywords = "Computer Science - Computer Vision and Pattern Recognition",
	month = feb,
	note = "arXiv: 1602.03409",
	shorttitle = "Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}",
	title = "{Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}: {CNN} {Architectures}, {Dataset} {Characteristics} and {Transfer} {Learning}}",
	url = "http://arxiv.org/abs/1602.03409",
	urldate = "2017-08-14",
	year = "2016"
}

@manual{shiny_2016,
	author = "Winston Chang and Joe Cheng and JJ Allaire and Yihui Xie and Jonathan McPherson",
	note = "R package version 0.14.2",
	title = "{shiny: Web Application Framework for R}",
	url = "https://CRAN.R-project.org/package=shiny",
	year = "2016"
}

@article{silva_forensic_2015,
	author = "Sarah S. Silva and C{\'a}tia Lopes and A.L. Teixeira and M.J Carneiro de Sousa and R. Medeiros",
	doi = "10.1016/j.fsigen.2014.09.002",
	issn = "18724973",
	journal = "Forensic Science International: Genetics",
	language = "en",
	month = jan,
	pages = "1--10",
	shorttitle = "Forensic {miRNA}",
	title = "{Forensic {miRNA}: {Potential} biomarker for body fluids?}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S1872497314001847",
	urldate = "2016-12-22",
	volume = "14",
	year = "2015"
}

@article{sing_rocr:_2005,
	abstract = "Summary: ROCR is a package for evaluating and visualizing the performance of scoring classifiers in the statistical language R. It features over 25 performance measures that can be freely combined to create two-dimensional performance curves. Standard methods for investigating trade-offs between specific performance measures are available within a uniform framework, including receiver operating characteristic (ROC) graphs, precision/recall plots, lift charts and cost curves. ROCR integrates tightly with R's powerful graphics capabilities, thus allowing for highly adjustable plots. Being equipped with only three commands and reasonable default values for optional parameters, ROCR combines flexibility with ease of usage.Availability:http://rocr.bioinf.mpi-sb.mpg.de. ROCR can be used under the terms of the GNU General Public License. Running within R, it is platform-independent.Contact:tobias.sing@mpi-sb.mpg.de",
	author = "Tobias Sing and Oliver Sander and Niko Beerenwinkel and Thomas Lengauer",
	doi = "10.1093/bioinformatics/bti623",
	issn = "1367-4803",
	journal = "Bioinformatics",
	month = oct,
	number = "20",
	pages = "3940--3941",
	shorttitle = "{ROCR}",
	title = "{{ROCR}: visualizing classifier performance in {R}}",
	url = "https://academic.oup.com/bioinformatics/article/21/20/3940/202693/ROCR-visualizing-classifier-performance-in-R",
	urldate = "2017-07-14",
	volume = "21",
	year = "2005"
}

@article{singer_characterization_1997,
	abstract = "A sensitive assay for detecting double-stranded (ds) DNA in solution is described. This assay employs a new dye, PicoGreen dsDNA quantitation reagent, which becomes intensely fluorescent upon binding nucleic acids. The brightness of this reagent is due to its high quantum yield (approximately 0.5, bound to ds calf thymus DNA) and large molar extinction coefficient (approximately 70,000 cm-1 M-1). The fluorescence enhancement of this dye upon binding dsDNA is {\textgreater} 1000-fold, with excitation and emission maxima near those of fluorescein. Unlike Hoechst 33258, PicoGreen reagent fluorescence intensity was the same upon binding to poly(dA).poly(dT) and poly(dG).poly(dC) homopolymers. The PicoGreen assay allowed the detection of 25 pg/ml dsDNA, surpassing the sensitivity achieved with Hoechst 33258 by 400-fold. The linear concentration range for DNA quantitation extended over four orders of magnitude-25 pg/ml to 1 microgram/ml-with a single dye concentration. Assay linearity was maintained even in the presence of salts, proteins, poly(ethylene glycol), urea, chloroform, ethanol, and agarose; some ionic detergents and heparin interfered. Linear DNAs yielded slightly brighter signals than supercoiled plasmids. Finally, the assay showed greater dsDNA:RNA selectivity than Hoechst 33258 in low ionic strength buffer and better dsDNA:single-stranded DNA selectivity in 1 M NaCl.",
	author = "V. L. Singer and L. J. Jones and S. T. Yue and R. P. Haugland",
	doi = "10.1006/abio.1997.2177",
	issn = "0003-2697",
	journal = "Analytical Biochemistry",
	keywords = "Fluorescent Dyes; Animals; DNA; Reproducibility of Results; Cattle; Organic Chemicals; Sensitivity and Specificity; Fluorometry; Indicators and Reagents; Solutions; Binding Sites; DNA; Single-Stranded; Drug Stability; Light",
	language = "eng",
	month = jul,
	number = "2",
	pages = "228--238",
	pmid = "9212875",
	title = "{Characterization of {PicoGreen} reagent and development of a fluorescence-based solution assay for double-stranded {DNA} quantitation}",
	volume = "249",
	year = "1997"
}

@article{sosnoski_melting_2002,
	author = "Donna M. Sosnoski and Esteban Parra and Jian Ye and Kevin Hiester and Mark D. Shriver and P. A. Underhill",
	file = "Ye et al. 2002.pdf:/home/tux/Work/Literatur/Zotero\_DB/zotero/storage/ZWDJH4I8/Ye et al. 2002.pdf:application/pdf",
	journal = "Journal of Forensic Science",
	number = "3",
	pages = "593--600",
	shorttitle = "Melting curve {SNP} ({McSNP}) genotyping",
	title = "{Melting curve {SNP} ({McSNP}) genotyping: a useful approach for diallelic genotyping in forensic science}",
	url = "http://www.astm.org/DIGITAL_LIBRARY/JOURNALS/FORENSIC/PAGES/JFS2001183.htm",
	urldate = "2016-12-21",
	volume = "47",
	year = "2002"
}

@article{sparkes_validation_1996,
	abstract = "PCR-based DNA typing of biological evidence is now widely used in forensic analyses due to the obvious advantages of enhanced sensitivity, the ability to distinguish discrete alleles and efficacy with degraded samples. A multiplex short tandem repeat (STR) system has been previously developed which successfully co-amplifies six STR loci HUMTH01, D21S11, D18S51, D8S1179, HUMVWF31/A and HUMFIBRA (FGA) in conjunction with the X-Y homologous gene Amelogenin. This is known as the second generation multiplex system (SGM). Detection of the PCR products is undertaken on ABD 373A or 377 automated sequencers using denaturing polyacrylamide gels coupled with fluorescent-based technology. We have evaluated this system for routine forensic use and demonstrated that the technique is robust and reproducible under conditions consistent with those encountered in a forensic environment. A total of 132 stains from simulated and actual casework were analysed, together with relevant control areas and reference samples. The success rate was high with 76\% of stains giving full profiles; we were also able to successfully detect and interpret mixtures. No mistyping was observed. A detailed examination of each of these profiles has assisted in the development of guidelines for casework interpretation. Although artefacts, stutter peaks and undenatured DNA were occasionally observed, these did not interfere with the accuracy of interpretation. In addition 38 samples, previously examined using the quadruplex system, were analysed with the SGM to enable a direct comparison to be made between the systems. The performance of the system with poor quality samples demonstrated its use as a rapid and powerful technique for individual identification.",
	author = "R. Sparkes and C. Kimpton and S. Gilbard and P. Carne and J. Anderson and N. Oldroyd and D. Thomas and A. Urquhart and P. Gill",
	doi = "10.1007/BF01225518",
	issn = "0937-9827, 1437-1596",
	journal = "International Journal of Legal Medicine",
	language = "en",
	month = dec,
	number = "4",
	pages = "195--204",
	title = "{The validation of a 7-locus multiplex {STIR} test for use in forensic casework}",
	url = "http://link.springer.com/article/10.1007/BF01225518",
	urldate = "2016-12-04",
	volume = "109",
	year = "1996"
}

@article{swango_developmental_2007,
	abstract = "Forensic scientists are constantly searching for better, faster, and less expensive ways to increase the first-pass success rate of forensic sample analysis. Technological advances continue to increase the sensitivity of analysis methods to enable genotyping of samples containing minimal amounts of DNA, yet few tools are available that can simultaneously alert the analyst to both the presence of inhibition and level of degradation in samples prior to genotyping to allow analysts the opportunity to make appropriate modifications to their protocols and, consequently, to use less sample. Our laboratory developed a multiplex quantitative PCR assay that amplifies two human nuclear DNA target sequences of different length to assess DNA degradation and a third amplification target, a synthetic oligonucleotide internal PCR control (IPC), to allow for the assessment of PCR inhibition. We chose the two nuclear targets to provide quantity and fragment-length information relevant to the STR amplification targets commonly used for forensic genotyping. The long target (nuTH01, 170--190 bp) spans the TH01 STR locus and uses a FAM-labeled TaqManÂ® probe for detection. The short nuclear target (nuCSF, 67 bp) is directed at the upstream flanking region of the CSF1PO STR locus and is detected using a VIC-labeled TaqManMGBÂ® probe. The IPC target sequence is detected using a NED-labeled TaqManMGBÂ® probe. The assay was validated on the Applied Biosystems 7500 Real-Time PCR system, which is optimized for NED detection. We report the results of a developmental validation in which the assay was rigorously tested, in accordance with the current SWGDAM guidelines, for precision, sensitivity, accuracy, reproducibility, species specificity, and stability.",
	author = "Katie L. Swango and William R. Hudlow and Mark D. Timken and Martin R. Buoncristiani",
	doi = "10.1016/j.forsciint.2006.09.002",
	issn = "0379-0738",
	journal = "Forensic Science International",
	keywords = "CSF; Degraded DNA; DNA quantitation; Forensic Sciences; Quantitative polymerase chain reaction; TH01",
	month = jul,
	number = "1",
	pages = "35--45",
	title = "{Developmental validation of a multiplex {qPCR} assay for assessing the quantity and quality of nuclear {DNA} in forensic samples}",
	url = "http://www.sciencedirect.com/science/article/pii/S0379073806005767",
	urldate = "2016-12-03",
	volume = "170",
	year = "2007"
}

@article{templ_exploring_2012,
	author = "Matthias Templ and Andreas Alfons and Peter Filzmoser",
	doi = "10.1007/s11634-011-0102-y",
	issn = "1862-5347, 1862-5355",
	journal = "Advances in Data Analysis and Classification",
	language = "en",
	month = apr,
	number = "1",
	pages = "29--47",
	title = "{Exploring incomplete data using visualization techniques}",
	url = "http://link.springer.com/10.1007/s11634-011-0102-y",
	urldate = "2017-08-28",
	volume = "6",
	year = "2012"
}

@article{tolson_machine_2001,
	author = "Edward Tolson",
	journal = "Advanced Undergraduate Project, Spring",
	title = "{Machine {Learning} in the area of image analysis and pattern recognition}",
	url = "https://stuff.mit.edu/afs/athena/course/urop/profit/PDFS/EdwardTolson.pdf",
	urldate = "2017-03-02",
	year = "2001"
}

@article{untergasser_2007,
	abstract = "Here we present {Primer3Plus}, a new web interface to the popular Primer3 primer design program as an enhanced alternative for the {CGI}- scripts that come with Primer3. Primer3 consists of a command line program and a web interface. The web interface is one large form showing all of the possible options. This makes the interface powerful, but at the same time confusing for occasional users. Primer3Plus provides an intuitive user interface using present-day web technologies and has been developed in close collaboration with molecular biologists and technicians regularly designing primers. It focuses on the task at hand, and hides detailed settings from the user until these are needed. We also added functionality to automate specific tasks like designing primers for cloning or step-wise sequencing. Settings and designed primer sequences can be stored locally for later use. Primer3Plus supports a range of common sequence formats, such as {FASTA}. Finally, primers selected by Primer3Plus can be sent to an order form, allowing tight integration into laboratory ordering systems. Moreover, the open architecture of Primer3Plus allows easy expansion or integration of external software packages. The Primer3Plus Perl source code is available under {GPL} license from {SourceForge}. Primer3Plus is available at http://www.bioinformatics.nl/primer3plus.",
	author = "Andreas Untergasser and Harm Nijveen and Xiangyu Rao and Ton Bisseling and Ren{\'e} Geurts and Jack A. M. Leunissen",
	doi = "10.1093/nar/gkm306",
	issn = "0305-1048, 1362-4962",
	journal = "Nucleic Acids Research",
	language = "en",
	month = jul,
	number = "suppl 2",
	pages = "W71--W74",
	pmid = "17485472",
	title = "{{Primer3Plus}, an enhanced web interface to {Primer3}}",
	url = "http://nar.oxfordjournals.org/content/35/suppl_2/W71",
	urldate = "2014-09-11",
	volume = "35",
	year = "2007"
}

@article{vennemann_mrna_2010,
	author = "Marielle Vennemann and Antje Koppelkamm",
	doi = "10.1016/j.forsciint.2010.07.006",
	issn = "03790738",
	journal = "Forensic Science International",
	language = "en",
	month = dec,
	number = "1-3",
	pages = "71--75",
	shorttitle = "{mRNA} profiling in forensic genetics {I}",
	title = "{{mRNA} profiling in forensic genetics {I}: {Possibilities} and limitations}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S037907381000335X",
	urldate = "2016-12-16",
	volume = "203",
	year = "2010"
}

@article{vera_r_parallel_2008,
	abstract = "R is the preferred tool for statistical analysis of many bioinformaticians due in part to the increasing number of freely available analytical methods. Such methods can be quickly reused and adapted to each particular experiment. However, in experiments where large amounts of data are generated, for example using high-throughput screening devices, the processing time required to analyze data is often quite long. A solution to reduce the processing time is the use of parallel computing technologies. Because R does not support parallel computations, several tools have been developed to enable such technologies. However, these tools require multiple modications to the way R programs are usually written or run. Although these tools can finally speed up the calculations, the time, skills and additional resources required to use them are an obstacle for most bioinformaticians.",
	author = "Gonzalo Vera and Ritsert C. Jansen and Remo L. Suppi",
	doi = "10.1186/1471-2105-9-390",
	issn = "1471-2105",
	journal = "BMC Bioinformatics",
	month = sep,
	pages = "390",
	title = "{R/parallel -- speeding up bioinformatics analysis with {R}}",
	url = "http://dx.doi.org/10.1186/1471-2105-9-390",
	urldate = "2017-07-09",
	volume = "9",
	year = "2008"
}

@article{verrecas_forensic_2004,
	author = "M Verrecas and K Knaepen and A Gilissen and J.-J Cassiman and R Decorte",
	doi = "10.1016/S0531-5131(03)01775-8",
	issn = "05315131",
	journal = "International Congress Series",
	language = "en",
	month = apr,
	pages = "583--585",
	shorttitle = "Forensic toxicology",
	title = "{Forensic toxicology: development of an {SNP}-assay for genotyping {CYP}2D6 and {CYP}2C19 variants}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S0531513103017758",
	urldate = "2016-12-22",
	volume = "1261",
	year = "2004"
}

@book{wickham_ggplot2_2016,
	abstract = "This new edition to the classic book by ggplot2 creator Hadley Wickham highlights compatibility with knitr and RStudio. ggplot2 is a data visualization package for R that helps users create data graphics, including those that are multi-layered, with ease. With ggplot2, it's easy to:produce handsome, publication-quality plots with automatic legends created from the plot specificationsuperimpose multiple layers (points, lines, maps, tiles, box plots) from different data sources with automatically adjusted common scalesadd customizable smoothers that use powerful modeling capabilities of R, such as loess, linear models, generalized additive models, and robust regressionsave any ggplot2 plot (or part thereof) for later modification or reusecreate custom themes that capture in-house or journal style requirements and that can easily be applied to multiple plotsapproach a graph from a visual perspective, thinking about how each component of the data is represented on the final plotThis book will be useful to everyone who has struggled with displaying data in an informative and attractive way. Some basic knowledge of R is necessary (e.g., importing data into R). ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, and you'll find it easy to get graphics out of your head and on to the screen or page.",
	address = "Cham",
	author = "Hadley Wickham",
	edition = "2nd ed. 2016 edition",
	isbn = "978-3-319-24275-0",
	language = "English",
	month = jun,
	publisher = "Springer",
	shorttitle = "ggplot2",
	title = "{{ggplot2}: {Elegant} {Graphics} for {Data} {Analysis}}",
	year = "2016"
}

@article{williams_rattle:_2009,
	author = "Graham J. Williams",
	journal = "The R Journal",
	month = dec,
	number = "2",
	pages = "45--55",
	title = "{Rattle: {A} {Data} {Mining} {GUI} for {R}}",
	url = "http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf",
	volume = "1",
	year = "2009"
}

@article{wittwer_high-resolution_2009,
	abstract = "Recent advances in fluorescent dyes, methods, instruments and software for {DNA} melting analysis have created versatile new tools for variant scanning and genotyping. High resolution melting analysis ({HRM} or {HRMA}) is faster, simpler, and less expensive than alternative approaches requiring separations or labeled probes. With the addition of a saturating dye before {PCR} followed by rapid melting analysis of the {PCR} products, the sensitivity of heterozygote scanning approaches 100\%. Specificity can be increased by identifying common polymorphisms with small amplicon melting, unlabeled probes or snapback primers to decrease the sequencing burden. However, some homozygotes require mixing for identification. Furthermore, different heterozygotes may produce melting curves so similar to each other that, although they clearly vary from homozygous variants, they are not differentiated from each other. Nevertheless, the experimental return for minimal effort is great. This focus issue of Human Mutation includes a concise, timely review on high resolution melting, a comparison to denaturing gradient gel electrophoresis, integration with {qPCR} for copy number assessment, combined amplicon scanning and unlabeled probe genotyping from a single melting curve, and applications to the mitochondrial genome and to {BRCA}1. Hum Mutat 30, 857--859, 2009. Â© 2009 Wiley-Liss, Inc.",
	author = "Carl T. Wittwer",
	date = "2009",
	doi = "10.1002/humu.20951",
	issn = "1098-1004",
	journaltitle = "Human Mutation",
	keywords = "Heterozygote scanning; {HRM}; {HRMA}; snapback primer; variant detection",
	langid = "english",
	number = "6",
	pages = "857--859",
	rights = "Â© 2009 Wiley-Liss, Inc.",
	shortjournal = "Hum. Mutat.",
	shorttitle = "High-resolution {DNA} melting analysis",
	title = "{High-resolution {DNA} melting analysis: advancements and limitations}",
	url = "http://onlinelibrary.wiley.com/doi/10.1002/humu.20951/abstract",
	urldate = "2014-09-11",
	volume = "30"
}

@article{wurmb-schwark_quantification_2002,
	abstract = "Recently, a moderately priced machine for real-time quantitative PCR has become available, the Perkin Elmer 5700. The rapid and quantitative assay of mitochondrial DNA (mtDNA) copy number is potentially useful in a variety of molecular, evolutionary and forensic fields. Using this new tool, we have evaluated the precision and reliability of the real time PCR to quantify undeleted mitochondrial genome copy number, and to determine the frequency of an age-associated deletion of 4977 base pairs in length, in 42 human iliopsoas muscle DNA samples from persons of known age.",
	author = "N. von Wurmb-Schwark and R. Higuchi and A. P. Fenech and C. Elfstroem and C. Meissner and M. Oehmichen and G. A. Cortopassi",
	doi = "10.1016/S0379-0738(02)00026-9",
	issn = "0379-0738, 1872-6283",
	journal = "Forensic Science International",
	language = "English",
	month = mar,
	number = "1",
	pages = "34--39",
	pmid = "11955829, 11955829",
	title = "{Quantification of human mitochondrial {DNA} in a real time {PCR}}",
	url = "/article/S0379-0738(02)00026-9/abstract",
	urldate = "2016-12-16",
	volume = "126",
	year = "2002"
}

@book{xml_book,
	abstract = "Web technologies are increasingly relevant to scientists working with data, for both accessing data and creating rich dynamic and interactive displays. The XML and JSON data formats are widely used in Web services, regular Web ...",
	author = "Deborah Nolan and Duncan Temple Lang",
	isbn = "978-1-4614-7900-0",
	keywords = "Compilers; Interpreters; Programming Languages; Statistics and Computing / Statistics Programs; XML and Web Technologies for Data Sciences with R",
	publisher = "Springer",
	title = "{{XML} and {Web} {Technologies} for {Data} {Sciences} with {R}}",
	url = "http://www.springer.com/statistics/computational+statistics/book/978-1-4614-7899-7",
	year = "2014"
}

@article{yang_application_2014,
	abstract = "Next-generation sequencing (NGS) technology, with its high-throughput capacity and low cost, has developed rapidly in recent years and become an important analytical tool for many genomics researchers. New opportunities in the research domain of the forensic studies emerge by harnessing the power of NGS technology, which can be applied to simultaneously analyzing multiple loci of forensic interest in different genetic contexts, such as autosomes, mitochondrial and sex chromosomes. Furthermore, NGS technology can also have potential applications in many other aspects of research. These include DNA database construction, ancestry and phenotypic inference, monozygotic twin studies, body fluid and species identification, and forensic animal, plant and microbiological analyses. Here we review the application of NGS technology in the field of forensic science with the aim of providing a reference for future forensics studies and practice.",
	author = "Yaran Yang and Bingbing Xie and Jiangwei Yan",
	doi = "10.1016/j.gpb.2014.09.001",
	issn = "1672-0229",
	journal = "Genomics, Proteomics \& Bioinformatics",
	keywords = "Forensics; Next-generation sequencing; Degradation of DNA; Genomics",
	month = oct,
	number = "5",
	pages = "190--197",
	series = "{Special {Issue}: {Translational} {Omics}}",
	title = "{Application of {Next}-generation {Sequencing} {Technology} in {Forensic} {Science}}",
	url = "http://www.sciencedirect.com/science/article/pii/S1672022914001053",
	urldate = "2017-12-22",
	volume = "12",
	year = "2014"
}

@article{zeller_pmml:_2009,
	author = "Michael Zeller and Wen-Ching Lin Alex Guazzelli and Graham Williams",
	journal = "The R Journal",
	month = jun,
	number = "1",
	pages = "60--65",
	title = "{{PMML}: {An} {Open} {Standard} for {Sharing} {Models}}",
	url = "http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Guazzelli+et+al.pdf",
	volume = "1",
	year = "2009"
}

@book{zielesny_curve_2011,
	address = "Berlin, Heidelberg",
	author = "Achim Zielesny",
	editor = "Janusz Kacprzyk and Lakhmi C. Jain",
	isbn = "978-3-642-21279-6 978-3-642-21280-2",
	note = "DOI: 10.1007/978-3-642-21280-2",
	publisher = "Springer Berlin Heidelberg",
	series = "{Intelligent {Systems} {Reference} {Library}}",
	title = "{From {Curve} {Fitting} to {Machine} {Learning}}",
	url = "http://link.springer.com/10.1007/978-3-642-21280-2",
	urldate = "2017-06-25",
	volume = "18",
	year = "2011"
}

@manual{Seibelt_xray,
	author = "Pablo Seibelt",
	note = "R package version 0.2",
	title = "{{xray}: X Ray Vision on your Datasets}",
	url = "https://CRAN.R-project.org/package=xray",
	year = "2017"
}

@article{karsai_evaluation_2002,
	abstract = "Real-time PCR is an accurate method that can be used for the quantification of specific DNA molecules. Here we provide a protocol for SYBRÂ® Green I in real-time PCR applications using plastic reaction tubes. We report that SYBR Green I is alkali labile and once degraded inhibits the PCR. In our optimized protocol, diluted aliquots of SYBR Green I remain stable for at least two weeks. We also evaluated different cDNA synthesis protocols for the quantification of multiple genes from the same cDNA preparation. The best result was obtained with cDNAs synthesized by OmniScriptâ„¢ reverse transcriptase from 2.5 Î¼g total RNA using oligo d(T)18 primers. The cDNA reactions could be diluted 1:25, allowing the quantification of up to 125 different medium expressed genes of Arabidopsis. Extension times ranged between 20 and 40 bp/s for accurate quantification of PCR products up to approximately 400 bp in the Rotor-Gene 2000 system. Using our optimized real-time PCR protocol, the reproducibility and amplification efficiency was high and comparable to a commercially available SYBR Green I kit. Furthermore, the sensitivity allowed us to quantify 10--20 copies of mRNA and dsDNA. Thus, the protocol eliminates the need for expensive pre-made kits.",
	author = "Albert Karsai and Sabine M{\"u}ller and Stefan Platz and Marie-Theres Hauser",
	issn = "0736-6205",
	journal = "BioTechniques",
	month = apr,
	number = "4",
	pages = "790--796",
	pmcid = "PMC4353838",
	pmid = "11962601",
	title = "{Evaluation of a {Homemade} {SYBR}Â® {Green} {I} {Reaction} {Mixture} for {Real}-{Time} {PCR} {Quantification} of {Gene} {Expression}}",
	url = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4353838/",
	urldate = "2018-01-10",
	volume = "32",
	year = "2002"
}

@article{wickham_testthat_2011,
	author = "Hadley Wickham",
	journal = "The R Journal",
	month = jun,
	number = "1",
	pages = "5--10",
	title = "{testthat: {Get} {Started} with {Testing}}",
	url = "http://journal.r-project.org/archive/2011/RJ-2011-002/index.html",
	volume = "3",
	year = "2011"
}

@book{myers_art_2004,
	address = "Hoboken, N.J",
	author = "Glenford J. Myers and Tom Badgett and Todd M. Thomas and Corey Sandler",
	edition = "2nd ed",
	isbn = "978-0-471-46912-4",
	keywords = "Computer software; Debugging in computer science; Testing",
	publisher = "John Wiley \& Sons",
	title = "{The art of software testing}",
	year = "2004"
}

@article{kemperman_mircomp-shiny:_2017,
	author = "Lauren Kemperman and Matthew N. McCall",
	issn = "2046-1402",
	journal = "F1000Research",
	language = "en",
	month = nov,
	pages = "2046",
	shorttitle = "{miRcomp}-{Shiny}",
	title = "{{miRcomp}-{Shiny}: {Interactive} assessment of {qPCR}-based {microRNA} quantification and quality control algorithms}",
	url = "https://f1000research.com/articles/6-2046/v1",
	urldate = "2017-12-10",
	volume = "6",
	year = "2017"
}

@book{de_vries_r_2012,
	author = "Andrie {De Vries} and Joris Meys",
	edition = "2",
	isbn = "978-1-119-96284-7",
	publisher = "John Wiley \& Sons",
	title = "{R for {Dummies}}",
	year = "2012"
}

@inproceedings{luo_learning_2010,
	author = "Ping Luo and Liang Lin and Hongyang Chao",
	booktitle = "{European {Conference} on {Computer} {Vision}}",
	pages = "342--355",
	publisher = "Springer",
	title = "{Learning shape detector by quantizing curve segments with multiple distance metrics}",
	year = "2010"
}

@book{kitchin2014,
	address = "Los Angeles, California London",
	author = "Rob Kitchin",
	isbn = "1446287483",
	publisher = "SAGE Publications",
	title = "{The data revolution : big data, open data, data infrastructures \& their consequences}",
	year = "2014"
}

@article{rote_computing_1991,
	abstract = "Given two sets of points on a line, we want to translate one of them so that their Hausdorff distance (the maximum of the distances from a point in any of the sets to the nearest point in the other set) is as small as possible. We present an optimal O(n log n) algorithm for this problem.",
	author = "G{\"u}nter Rote",
	doi = "10.1016/0020-0190(91)90233-8",
	issn = "0020-0190",
	journal = "Information Processing Letters",
	keywords = "Computational geometry; Hausdorff distance; pattern matching; pattern recognition",
	month = may,
	number = "3",
	pages = "123--127",
	title = "{Computing the minimum {Hausdorff} distance between two point sets on a line under translation}",
	url = "http://www.sciencedirect.com/science/article/pii/0020019091902338",
	urldate = "2018-02-12",
	volume = "38",
	year = "1991"
}

@article{nolan_2006,
	author = "Tania Nolan and Rebecca E Hands and Stephen A Bustin",
	journal = "Nature Protocols",
	month = nov,
	pages = "1559",
	title = "{Quantification of {mRNA} using real-time {RT}-{PCR}}",
	url = "http://dx.doi.org/10.1038/nprot.2006.236",
	volume = "1",
	year = "2006"
}

@article{isaac_essentials_2009,
	author = "Peter G. Isaac",
	doi = "10.1093/aob/mcp135",
	issn = "1095-8290, 0305-7364",
	journal = "Annals of Botany",
	language = "en",
	month = aug,
	number = "2",
	pages = "vi--vi",
	shorttitle = "Essentials of nucleic acid analysis",
	title = "{Essentials of nucleic acid analysis: a robust approach}",
	url = "https://academic.oup.com/aob/article-lookup/doi/10.1093/aob/mcp135",
	urldate = "2017-09-05",
	volume = "104",
	year = "2009"
}

@article{reshef_detecting_2011,
	author = "David N. Reshef and Yakir A. Reshef and Hilary K. Finucane and Sharon R. Grossman and Gilean McVean and Peter J. Turnbaugh and Eric S. Lander and Michael Mitzenmacher and Pardis C. Sabeti",
	journal = "science",
	number = "6062",
	pages = "1518--1524",
	title = "{Detecting novel associations in large data sets}",
	volume = "334",
	year = "2011"
}

@article{walsh_correct_2015,
	abstract = "Machine learning methods are becoming increasingly popular to predict protein features from sequences. Machine learning in bioinformatics can be powerful but carries also the risk of introducing unexpected biases, which may lead to an overestimation of the performance. This article espouses a set of guidelines to allow both peer reviewers and authors to avoid common machine learning pitfalls. Understanding biology is necessary to produce useful data sets, which have to be large and diverse. Separating the training and test process is imperative to avoid over-selling method performance, which is also dependent on several hidden parameters. A novel predictor has always to be compared with several existing methods, including simple baseline strategies. Using the presented guidelines will help nonspecialists to appreciate the critical issues in machine learning.",
	author = "Ian Walsh and Gianluca Pollastri and Silvio C. E. Tosatto",
	doi = "10.1093/bib/bbv082",
	issn = "1467-5463, 1477-4054",
	journal = "Briefings in Bioinformatics",
	keywords = "machine learning; protein sequence; posttranslational modification; predictor; training; evaluation",
	language = "en",
	month = sep,
	pages = "bbv082",
	pmid = "26411473",
	shorttitle = "Correct machine learning on protein sequences",
	title = "{Correct machine learning on protein sequences: a peer-reviewing perspective}",
	url = "http://bib.oxfordjournals.org/content/early/2015/09/25/bib.bbv082",
	urldate = "2016-05-13",
	year = "2015"
}

@incollection{mcfadden_conditional_1974,
	author = "Daniel L. McFadden",
	booktitle = "{Frontiers in {Economics}}",
	pages = "105--142",
	publisher = "New York: Academic Press",
	series = "{P. {Zarembka} (ed.)}",
	title = "{Conditional {Logit} {Analysis} of {Qualitative} {Choice} {Behavior}}",
	url = "https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf",
	urldate = "2018-03-03",
	volume = "Frontiers in Economics",
	year = "1974"
}

@article{tichopad_standardized_2003,
	abstract = "We propose a computing method for the estimation of real-time PCR amplification efficiency. It is based on a statistic delimitation of the beginning of exponentially behaving observations in real-time PCR kinetics. PCR ground fluorescence phase, non-exponential and plateau phase were excluded from the calculation process by separate mathematical algorithms. We validated the method on experimental data on multiple targets obtained on the LightCycler platform. The developed method yields results of higher accuracy than the currently used method of serial dilutions for amplification efficiency estimation. The single reaction set-up estimation is sensitive to differences in starting concentrations of the target sequence in samples. Furthermore, it resists the subjective influence of researchers, and the estimation can therefore be fully instrumentalized.",
	author = "Ales Tichopad and Michael Dilger and Gerhard Schwarz and Michael W Pfaffl",
	issn = "1362-4962",
	journal = "Nucleic acids research",
	keywords = "Animals; DNA; Fluorescence; Plasmids; Reference Standards; Polymerase chain reaction; Reproducibility of Results; Algorithms; Cattle; Genes; sry; Organic Chemicals; Sensitivity and Specificity",
	language = "eng",
	month = oct,
	number = "20",
	pages = "e122",
	pmcid = "PMC219490",
	pmid = "14530455",
	title = "{Standardized determination of real-time {PCR} efficiency from a single reaction set-up}",
	volume = "31",
	year = "2003"
}

